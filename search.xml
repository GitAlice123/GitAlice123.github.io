<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CUDA编程模型</title>
    <url>/2024/12/08/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p><a class="link"   href="https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/" >https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/<i class="fa-solid fa-arrow-up-right ml-[0.2em] font-light align-text-top text-[0.7em] link-icon"></i></a></p>
<ul>
<li>一组<strong>线程</strong>组成一个<strong>CUDA block</strong></li>
<li>一组<strong>CUDA block</strong>组成一个<strong>CUDA grid</strong></li>
</ul>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/CUDAkernel.png"
                      width="50%"
                >

<ul>
<li>每个CUDA block只能在一个CUDA SM上执行，不可以跨SM</li>
<li>每个SM可以跑多个并发的CUDA block</li>
<li>每个线程可以用一个三维的索引来标识自己的位置，比如<code>threadIdx.x</code>, <code>threadIdx.y</code>, <code>threadIdx.z</code></li>
</ul>
]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>NCCL代码阅读-01</title>
    <url>/2024/11/28/NCCL%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB-01/</url>
    <content><![CDATA[<h2 id="创建一个通信组-communicator"><a href="#创建一个通信组-communicator" class="headerlink" title="创建一个通信组(communicator)"></a>创建一个通信组(communicator)</h2><ul>
<li>创建一个通信组之前，每个CUDA设备都要被分配一个唯一的rank id</li>
<li>有了这个rank id和CUDA设备的静态映射，ncclCommInitRank(), ncclCommInitRankConfig() and ncclCommInitAll() 三个函数会创建communicator objects，每个communicator object会和一个固定的rank（及一个CUDA设备）关联。</li>
<li>在调用ncclCommInitRank之前，需要调用ncclGetUniqueId()来获取一个unique id，这个ID必须广播到所有参与通信的进程，让他们知道自己在communicator中</li>
<li>比如有四个GPU互相通信，加入了一个通信组，那么这个通信组就需要一个通信上下文记录所有的信息</li>
<li>类比四个人开会，那么这个通信上下文就是会议室</li>
</ul>
<h3 id="ncclCommInitRank"><a href="#ncclCommInitRank" class="headerlink" title="ncclCommInitRank"></a>ncclCommInitRank</h3><div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">ncclResult_t <span class="title function_">ncclCommInitRank</span><span class="params">(ncclComm_t* comm, <span class="type">int</span> nranks, ncclUniqueId commId, <span class="type">int</span> rank)</span></span><br></pre></td></tr></table></figure></div>
<ul>
<li>创建一个communicator object</li>
<li>里面调用ncclCommInitRankDev()</li>
</ul>
<h3 id="ncclCommInitAll"><a href="#ncclCommInitAll" class="headerlink" title="ncclCommInitAll"></a>ncclCommInitAll</h3><ul>
<li>在<strong>一个CPU进程</strong>里面执行(<strong>因此他后面所调用的所有函数都是在这一个进程，一个线程里面执行的</strong>)，创建多个communicator object</li>
<li>但是只能是单进程版本，也因此不支持多node通信</li>
<li>首先检查了各种数据的有效性</li>
<li>然后调用ncclGetUniqueId()获取一个unique id<ul>
<li>ncclGetUniqueId()首先调用ncclInit()初始化NCCL</li>
</ul>
</li>
</ul>
<h3 id="ncclInit"><a href="#ncclInit" class="headerlink" title="ncclInit()"></a>ncclInit()</h3><ul>
<li>这是一个在所有线程中只会执行一次的函数</li>
<li>在两个地方被调用：ncclGetUniqueId和ncclCommInitRankDev</li>
<li>如果是ncclGetUniqueId调用的，那么分两种情况：<ul>
<li>在ncclCommInitAll中调用，那其实就一个进程，一个线程，不用担心会被多次调用</li>
<li>在ncclCommInitRank前面调用，那么就要限制只有第一个线程调用，后面的线程不会再调用</li>
</ul>
</li>
</ul>
<h2 id="SendRecv的调用流程"><a href="#SendRecv的调用流程" class="headerlink" title="SendRecv的调用流程"></a>SendRecv的调用流程</h2><ul>
<li><p>nccl-test中，sendrecv.cu</p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">testResult_t <span class="title function_">SendRecvRunColl</span><span class="params">(<span class="type">void</span> *sendbuff, <span class="type">void</span> *recvbuff, <span class="type">size_t</span> count, ncclDataType_t type, ncclRedOp_t op, <span class="type">int</span> root, ncclComm_t comm, cudaStream_t stream)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> nRanks;</span><br><span class="line">    NCCLCHECK(ncclCommCount(comm, &amp;nRanks));</span><br><span class="line">    <span class="type">int</span> rank;</span><br><span class="line">    NCCLCHECK(ncclCommUserRank(comm, &amp;rank));</span><br><span class="line">    <span class="type">int</span> recvPeer = (rank - <span class="number">1</span> + nRanks) % nRanks;</span><br><span class="line">    <span class="type">int</span> sendPeer = (rank + <span class="number">1</span>) % nRanks;</span><br><span class="line"></span><br><span class="line">    NCCLCHECK(ncclGroupStart());</span><br><span class="line">    <span class="comment">// 显式对sendPeer和recvPeer进行send和recv操作</span></span><br><span class="line">    NCCLCHECK(ncclSend(sendbuff, count, type, sendPeer, comm, stream));</span><br><span class="line">    NCCLCHECK(ncclRecv(recvbuff, count, type, recvPeer, comm, stream));</span><br><span class="line">    NCCLCHECK(ncclGroupEnd());</span><br><span class="line">    <span class="keyword">return</span> testSuccess;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
<li><p>nccl的collectives.cc中，注意在info里面传递的第一个参数是comm，也就是操作类型，后续在enqueucheck里面把操作类型用info传进去了</p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">ncclResult_t <span class="title function_">ncclSend</span><span class="params">(<span class="type">const</span> <span class="type">void</span> *sendbuff, <span class="type">size_t</span> count, ncclDataType_t datatype, <span class="type">int</span> peer,</span></span><br><span class="line"><span class="params">                      ncclComm_t comm, cudaStream_t stream)</span></span><br><span class="line">&#123;</span><br><span class="line">    NvtxParamsSendRecv payload&#123;count * <span class="title function_">ncclTypeSize</span><span class="params">(datatype)</span>, peer&#125;;</span><br><span class="line">    NVTX3_FUNC_WITH_PARAMS(Send, SendRecvSchema, payload)</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ncclInfo</span> <span class="title">info</span> =</span> &#123;ncclFuncSend, <span class="string">&quot;Send&quot;</span>,</span><br><span class="line">                            <span class="literal">NULL</span>, (<span class="type">void</span> *)sendbuff, count, datatype, ncclSum, peer, comm, stream, <span class="comment">/* Args */</span></span><br><span class="line">                            <span class="number">1</span>, <span class="number">1</span>&#125;;</span><br><span class="line">    ncclResult_t ret;</span><br><span class="line">    NCCLCHECK(ncclGroupStart());</span><br><span class="line">    NCCLCHECKGOTO(ncclEnqueueCheck(&amp;info), ret, <span class="built_in">exit</span>);</span><br><span class="line"><span class="built_in">exit</span>:</span><br><span class="line">    NCCLCHECK(ncclGroupEnd());</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
<li><p>nccl的enqueue.cc中</p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">ncclResult_t <span class="title function_">ncclEnqueueCheck</span><span class="params">(<span class="keyword">struct</span> ncclInfo *info)</span></span><br><span class="line">&#123;</span><br><span class="line">    NCCLCHECK(ncclGroupStartInternal());</span><br><span class="line">    ncclResult_t ret = ncclSuccess;</span><br><span class="line">    <span class="type">int</span> devOld = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    NCCLCHECKGOTO(CommCheck(info-&gt;comm, info-&gt;opName, <span class="string">&quot;comm&quot;</span>), ret, fail);</span><br><span class="line">    <span class="comment">// Check whether communicator is ready to communicate</span></span><br><span class="line">    NCCLCHECKGOTO(ncclCommEnsureReady(info-&gt;comm), ret, fail);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (info-&gt;comm-&gt;checkPointers)</span><br><span class="line">    &#123;</span><br><span class="line">        CUDACHECKGOTO(cudaGetDevice(&amp;devOld), ret, fail);</span><br><span class="line">        CUDACHECKGOTO(cudaSetDevice(info-&gt;comm-&gt;cudaDev), ret, fail);</span><br><span class="line">    &#125;</span><br><span class="line">    NCCLCHECKGOTO(ArgsCheck(info), ret, fail);</span><br><span class="line"></span><br><span class="line">    INFO(NCCL_COLL, <span class="string">&quot;%s: opCount %lx sendbuff %p recvbuff %p count %zu datatype %d op %d root %d comm %p [nranks=%d] stream %p&quot;</span>,</span><br><span class="line">         info-&gt;opName, info-&gt;comm-&gt;opCount, info-&gt;sendbuff, info-&gt;recvbuff, info-&gt;count,</span><br><span class="line">         info-&gt;datatype, info-&gt;op, info-&gt;root, info-&gt;comm, info-&gt;comm-&gt;nRanks, info-&gt;stream);</span><br><span class="line">    TRACE_CALL(<span class="string">&quot;nccl%s(%&quot;</span> PRIx64 <span class="string">&quot;,%&quot;</span> PRIx64 <span class="string">&quot;,%zu,%d,%d,%d,%p,%p)&quot;</span>, info-&gt;opName, reinterpret_cast&lt;<span class="type">int64_t</span>&gt;(info-&gt;sendbuff), reinterpret_cast&lt;<span class="type">int64_t</span>&gt;(info-&gt;recvbuff), info-&gt;count, info-&gt;datatype, info-&gt;op, info-&gt;root, info-&gt;comm, info-&gt;stream);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ！！！！！！！！！！！！！！！！！！！！！！！！！！</span></span><br><span class="line">    <span class="comment">// taskAppend把info转换成一个task，然后加入到comm-&gt;planner</span></span><br><span class="line">    <span class="comment">// 调用 ncclGroupCommJoin 将当前任务加入线程本地的通信组</span></span><br><span class="line">    <span class="comment">// 从内存池中分配一个 P2P 任务结构 (ncclTaskP2p) 并初始化任务</span></span><br><span class="line">    <span class="comment">// 将 P2P 任务添加到对应 peer 的发送队列或接收队列</span></span><br><span class="line">    <span class="comment">// 任务放入队列后，下面的groupEndInternal可见</span></span><br><span class="line">    NCCLCHECKGOTO(taskAppend(info-&gt;comm, info), ret, fail);</span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span>:</span><br><span class="line">    <span class="keyword">if</span> (devOld != <span class="number">-1</span>)</span><br><span class="line">        CUDACHECK(cudaSetDevice(devOld));</span><br><span class="line">    ncclGroupErrCheck(ret);</span><br><span class="line">    NCCLCHECK(ncclGroupEndInternal());</span><br><span class="line">    <span class="comment">/* if depth is 1, ncclGroupEndInternal() will trigger group ops. The state can change</span></span><br><span class="line"><span class="comment">     * so we have to check state here. */</span></span><br><span class="line">    <span class="keyword">if</span> (info-&gt;comm &amp;&amp; !info-&gt;comm-&gt;config.blocking)</span><br><span class="line">    &#123;</span><br><span class="line">        NCCLCHECK(ncclCommGetAsyncError(info-&gt;comm, &amp;ret));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">fail:</span><br><span class="line">    <span class="keyword">if</span> (info-&gt;comm &amp;&amp; !info-&gt;comm-&gt;config.blocking)</span><br><span class="line">        (<span class="type">void</span>)ncclCommSetAsyncError(info-&gt;comm, ret);</span><br><span class="line">    <span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

</li>
<li><p>nccl的group.cc中</p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">ncclResult_t <span class="title function_">ncclGroupEndInternal</span><span class="params">(ncclSimInfo_t *simInfo)</span></span><br><span class="line">&#123;</span><br><span class="line">    ncclResult_t ret = ncclSuccess;</span><br><span class="line">    ncclSimInfo_t internalSimInfo = NCCL_SIM_INFO_INITIALIZER;</span><br><span class="line">    ncclSimInfo_t *internalSimInfoPtr = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="type">size_t</span> realSize = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    internalSimInfo.magic = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ncclGroupDepth == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        WARN(<span class="string">&quot;ncclGroupEnd: not in a group call.&quot;</span>);</span><br><span class="line">        ret = ncclInvalidUsage;</span><br><span class="line">        <span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ((--ncclGroupDepth) &gt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ((ret = ncclGroupError) != ncclSuccess)</span><br><span class="line">        <span class="keyword">goto</span> fail;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (simInfo)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">memcpy</span>((<span class="type">void</span> *)&amp;realSize, (<span class="type">void</span> *)&amp;simInfo-&gt;size, <span class="keyword">sizeof</span>(<span class="type">size_t</span>));</span><br><span class="line">        realSize = realSize &gt; <span class="keyword">sizeof</span>(ncclSimInfo_t) ? <span class="keyword">sizeof</span>(ncclSimInfo_t) : realSize;</span><br><span class="line">        <span class="built_in">memcpy</span>((<span class="type">void</span> *)&amp;internalSimInfo, (<span class="type">void</span> *)simInfo, realSize);</span><br><span class="line">        <span class="keyword">if</span> (internalSimInfo.magic != <span class="number">0x74685283</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            WARN(<span class="string">&quot;ncclSimInfo_t argument not initialized via NCCL_SIM_INFO_INITIALIZER&quot;</span>);</span><br><span class="line">            ret = ncclInvalidArgument;</span><br><span class="line">            <span class="keyword">goto</span> fail;</span><br><span class="line">        &#125;</span><br><span class="line">        internalSimInfoPtr = &amp;internalSimInfo;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ncclGroupCommHead != nullptr || !ncclIntruQueueEmpty(&amp;ncclAsyncJobs) || ncclGroupCommPreconnectHead != nullptr)</span><br><span class="line">    &#123;</span><br><span class="line">        ncclGroupJobMain.groupCommHeadPtr = &amp;ncclGroupCommHead;</span><br><span class="line">        ncclGroupJobMain.groupCommPreconnectHeadPtr = &amp;ncclGroupCommPreconnectHead;</span><br><span class="line">        ncclGroupJobMain.groupErrorPtr = &amp;ncclGroupError;</span><br><span class="line">        ncclGroupJobMain.asyncJobsPtr = &amp;ncclAsyncJobs;</span><br><span class="line">        ncclGroupJobMain.abortFlagPtr = &amp;ncclGroupJobAbortFlag;</span><br><span class="line">        ncclGroupJobMain.groupBlockingPtr = &amp;ncclGroupBlocking;</span><br><span class="line">        ncclGroupJobMain.initialized = <span class="literal">true</span>;</span><br><span class="line">        ncclGroupJobMainPtr = &amp;ncclGroupJobMain;</span><br><span class="line">        <span class="comment">/* make sure ncclGroupBlocking has been set. */</span></span><br><span class="line">        assert(ncclGroupBlocking == <span class="number">0</span> || ncclGroupBlocking == <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">if</span> (ncclGroupBlocking == <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">/* nonblocking group */</span></span><br><span class="line">            <span class="keyword">if</span> (!ncclIntruQueueEmpty(&amp;ncclAsyncJobs))</span><br><span class="line">            &#123;</span><br><span class="line">                ncclAsyncJob *job = ncclIntruQueueHead(&amp;ncclAsyncJobs);</span><br><span class="line">                <span class="keyword">do</span></span><br><span class="line">                &#123;</span><br><span class="line">                    NCCLCHECKGOTO(ncclCommSetAsyncError(job-&gt;comm, ncclInProgress), ret, fail);</span><br><span class="line">                    job-&gt;comm-&gt;groupJob = ncclGroupJobMainPtr;</span><br><span class="line">                    job = job-&gt;next;</span><br><span class="line">                &#125; <span class="keyword">while</span> (job);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (ncclGroupCommHead)</span><br><span class="line">            &#123;</span><br><span class="line">                ncclComm_t comm = ncclGroupCommHead;</span><br><span class="line">                <span class="keyword">do</span></span><br><span class="line">                &#123;</span><br><span class="line">                    NCCLCHECKGOTO(ncclCommSetAsyncError(comm, ncclInProgress), ret, fail);</span><br><span class="line">                    <span class="comment">/* link group job to communicators. */</span></span><br><span class="line">                    comm-&gt;groupJob = ncclGroupJobMainPtr;</span><br><span class="line">                    comm = comm-&gt;groupNext;</span><br><span class="line">                &#125; <span class="keyword">while</span> (comm);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            ncclGroupJobMainPtr-&gt;base.func = groupLaunchNonBlocking;</span><br><span class="line">            PTHREADCHECKGOTO(pthread_create(&amp;ncclGroupJobMainPtr-&gt;base.thread, <span class="literal">NULL</span>, ncclAsyncJobMain, (<span class="type">void</span> *)&amp;ncclGroupJobMainPtr-&gt;base), <span class="string">&quot;pthread_create&quot;</span>, ret, fail);</span><br><span class="line">            ret = ncclInProgress;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">/* blocking group */</span></span><br><span class="line">            NCCLCHECKGOTO(groupLaunch(&amp;ncclGroupJobMainPtr-&gt;base, internalSimInfoPtr), ret, fail);</span><br><span class="line">            <span class="keyword">if</span> (simInfo)</span><br><span class="line">                <span class="built_in">memcpy</span>((<span class="type">void</span> *)simInfo, (<span class="type">void</span> *)internalSimInfoPtr, realSize);</span><br><span class="line">            groupResetJobState(ncclGroupJobMainPtr);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span>:</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">fail:</span><br><span class="line">    groupCleanup(&amp;ncclGroupCommHead, &amp;ncclGroupCommPreconnectHead, &amp;ncclAsyncJobs, &amp;ncclGroupError, &amp;ncclGroupBlocking, &amp;ncclGroupJobAbortFlag, ret);</span><br><span class="line">    <span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
<li><p>group.cc中</p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> ncclResult_t <span class="title function_">groupLaunch</span><span class="params">(<span class="keyword">struct</span> ncclAsyncJob *job_, ncclSimInfo_t *simInfo = <span class="literal">NULL</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> savedDev;</span><br><span class="line">    ncclResult_t ret = ncclSuccess;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ncclGroupJob</span> *<span class="title">gjob</span> =</span> (<span class="keyword">struct</span> ncclGroupJob *)job_;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ncclComm</span> *<span class="title">groupCommHeadMain</span> =</span> *gjob-&gt;groupCommHeadPtr;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ncclComm</span> *<span class="title">groupCommPreconnectHeadMain</span> =</span> *gjob-&gt;groupCommPreconnectHeadPtr;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ncclIntruQueue</span>&lt;</span><span class="class"><span class="keyword">struct</span> <span class="title">ncclAsyncJob</span>, &amp;<span class="title">ncclAsyncJob</span>:</span>:next&gt; *asyncJobsMain = gjob-&gt;asyncJobsPtr;</span><br><span class="line"></span><br><span class="line">    <span class="type">bool</span> *groupAbortFlag = gjob-&gt;abortFlagPtr;</span><br><span class="line"></span><br><span class="line">    CUDACHECKGOTO(cudaGetDevice(&amp;savedDev), ret, fail);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!simInfo &amp;&amp; groupCommPreconnectHeadMain != nullptr)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">ncclComm</span> *<span class="title">comm</span> =</span> groupCommPreconnectHeadMain;</span><br><span class="line">        <span class="keyword">do</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="class"><span class="keyword">struct</span> <span class="title">ncclPreconnectJob</span> *<span class="title">job</span>;</span></span><br><span class="line">            NCCLCHECKGOTO(ncclCalloc(&amp;job, <span class="number">1</span>), ret, fail);</span><br><span class="line">            job-&gt;base.func = ncclP2PPreconnectFunc;</span><br><span class="line">            job-&gt;base.undo = nullptr;</span><br><span class="line">            job-&gt;base.destructor = <span class="built_in">free</span>;</span><br><span class="line">            job-&gt;base.state = ncclGroupJobRunning;</span><br><span class="line">            job-&gt;base.abortFlag = comm-&gt;abortFlag;</span><br><span class="line">            job-&gt;base.abortFlagDev = comm-&gt;abortFlagDev;</span><br><span class="line">            job-&gt;comm = comm;</span><br><span class="line">            ncclIntruQueueEnqueue(asyncJobsMain, (<span class="keyword">struct</span> ncclAsyncJob *)job);</span><br><span class="line"></span><br><span class="line">            <span class="class"><span class="keyword">struct</span> <span class="title">ncclComm</span> *<span class="title">next</span> =</span> comm-&gt;preconnectNext;</span><br><span class="line">            comm-&gt;preconnectNext = reinterpret_cast&lt;<span class="keyword">struct</span> ncclComm *&gt;(<span class="number">0x1</span>);</span><br><span class="line">            comm = next;</span><br><span class="line">        &#125; <span class="keyword">while</span> (comm != nullptr);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    NCCLCHECKGOTO(asyncJobLaunch(asyncJobsMain, groupAbortFlag), ret, fail);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Connect channels at runtime if cumem is supported */</span></span><br><span class="line">    <span class="keyword">if</span> (groupCommHeadMain != nullptr)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">ncclComm</span> *<span class="title">comm</span> =</span> groupCommHeadMain;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">ncclIntruQueue</span>&lt;</span><span class="class"><span class="keyword">struct</span> <span class="title">ncclAsyncJob</span>, &amp;<span class="title">ncclAsyncJob</span>:</span>:next&gt; asyncCollJobs;</span><br><span class="line">        ncclIntruQueueConstruct(&amp;asyncCollJobs);</span><br><span class="line">        <span class="keyword">do</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">bool</span> needConnect = <span class="literal">false</span>;</span><br><span class="line">            <span class="type">bool</span> algoNeedConnect[NCCL_NUM_ALGORITHMS];</span><br><span class="line">            <span class="built_in">memset</span>(algoNeedConnect, <span class="number">0</span>, <span class="keyword">sizeof</span>(<span class="type">bool</span>) * NCCL_NUM_ALGORITHMS);</span><br><span class="line"></span><br><span class="line">            CUDACHECKGOTO(cudaSetDevice(comm-&gt;cudaDev), ret, fail);</span><br><span class="line">            NCCLCHECKGOTO(ncclPrepareTasks(comm, algoNeedConnect, &amp;needConnect, simInfo), ret, fail);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (comm-&gt;cuMemSupport &amp;&amp; needConnect)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="class"><span class="keyword">struct</span> <span class="title">ncclPreconnectJob</span> *<span class="title">job</span>;</span></span><br><span class="line">                NCCLCHECKGOTO(ncclCalloc(&amp;job, <span class="number">1</span>), ret, fail);</span><br><span class="line">                job-&gt;base.func = ncclCollPreconnectFunc;</span><br><span class="line">                job-&gt;base.undo = nullptr;</span><br><span class="line">                job-&gt;base.destructor = <span class="built_in">free</span>;</span><br><span class="line">                job-&gt;base.state = ncclGroupJobRunning;</span><br><span class="line">                job-&gt;base.abortFlag = comm-&gt;abortFlag;</span><br><span class="line">                job-&gt;base.abortFlagDev = comm-&gt;abortFlagDev;</span><br><span class="line">                job-&gt;comm = comm;</span><br><span class="line">                NCCLCHECKGOTO(ncclCalloc(&amp;job-&gt;algoNeedConnect, NCCL_NUM_ALGORITHMS), ret, fail);</span><br><span class="line">                <span class="built_in">memcpy</span>(job-&gt;algoNeedConnect, algoNeedConnect, <span class="keyword">sizeof</span>(<span class="type">bool</span>) * NCCL_NUM_ALGORITHMS);</span><br><span class="line">                ncclIntruQueueEnqueue(&amp;asyncCollJobs, &amp;job-&gt;base);</span><br><span class="line">            &#125;</span><br><span class="line">            comm = comm-&gt;groupNext;</span><br><span class="line">        &#125; <span class="keyword">while</span> (comm);</span><br><span class="line"></span><br><span class="line">        NCCLCHECKGOTO(asyncJobLaunch(&amp;asyncCollJobs, groupAbortFlag), ret, fail);</span><br><span class="line">        <span class="keyword">while</span> (!ncclIntruQueueEmpty(&amp;asyncCollJobs))</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="class"><span class="keyword">struct</span> <span class="title">ncclAsyncJob</span> *<span class="title">job</span> =</span> ncclIntruQueueDequeue(&amp;asyncCollJobs);</span><br><span class="line">            <span class="keyword">if</span> (job-&gt;destructor)</span><br><span class="line">                job-&gt;destructor((<span class="type">void</span> *)job);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ((!simInfo) &amp;&amp; (groupCommHeadMain != nullptr))</span><br><span class="line">    &#123;</span><br><span class="line">        NCCLCHECKGOTO(doLaunches(groupCommHeadMain), ret, fail);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (!ncclIntruQueueEmpty(asyncJobsMain))</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">ncclAsyncJob</span> *<span class="title">job</span> =</span> ncclIntruQueueDequeue(asyncJobsMain);</span><br><span class="line">        <span class="keyword">if</span> (!job-&gt;destroyFlag &amp;&amp; job-&gt;comm &amp;&amp; !job-&gt;comm-&gt;config.blocking)</span><br><span class="line">            (<span class="type">void</span>)ncclCommSetAsyncError(job-&gt;comm, ret);</span><br><span class="line">        <span class="keyword">if</span> (job-&gt;destructor)</span><br><span class="line">            job-&gt;destructor((<span class="type">void</span> *)job);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (groupCommHeadMain != nullptr)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">ncclComm</span> *<span class="title">comm</span> =</span> groupCommHeadMain;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">ncclComm</span> *<span class="title">next</span> =</span> comm-&gt;groupNext;</span><br><span class="line">        (<span class="type">void</span>)ncclGroupCommLeave(comm);</span><br><span class="line">        <span class="keyword">if</span> (!comm-&gt;config.blocking)</span><br><span class="line">        &#123;</span><br><span class="line">            (<span class="type">void</span>)ncclCommSetAsyncError(comm, ret);</span><br><span class="line">        &#125;</span><br><span class="line">        groupCommHeadMain = next;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    CUDACHECK(cudaSetDevice(savedDev));</span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span>:</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">fail:</span><br><span class="line">    groupCleanup(gjob-&gt;groupCommHeadPtr, gjob-&gt;groupCommPreconnectHeadPtr, gjob-&gt;asyncJobsPtr, gjob-&gt;groupErrorPtr, gjob-&gt;groupBlockingPtr, gjob-&gt;abortFlagPtr, ret);</span><br><span class="line">    <span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
<li><p>group.cc中</p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> ncclResult_t <span class="title function_">doLaunches</span><span class="params">(<span class="keyword">struct</span> ncclComm *head)</span></span><br><span class="line">&#123;</span><br><span class="line">    ncclResult_t result = ncclSuccess;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ncclComm</span> *<span class="title">cliqueComm0</span> =</span> head-&gt;intraComm0;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ncclComm</span> *<span class="title">cliqueHead</span> =</span> head;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ncclComm</span> *<span class="title">cliqueNextHead</span>;</span></span><br><span class="line">    <span class="type">bool</span> useBarrier = ncclParamLaunchMode == ncclLaunchModeGroup;</span><br><span class="line">    <span class="comment">// This outer loop iterates over cliques of comms which are siblings of the</span></span><br><span class="line">    <span class="comment">// same global entity. We calculate a clique as all comms which have the same</span></span><br><span class="line">    <span class="comment">// `intraComm0` value.</span></span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">ncclComm</span> *<span class="title">comm</span> =</span> cliqueHead;</span><br><span class="line">        <span class="type">bool</span> capturingYes = <span class="literal">false</span>, capturingNo = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">do</span></span><br><span class="line">        &#123;</span><br><span class="line">            (ncclCudaGraphValid(comm-&gt;planner.capturingGraph) ? capturingYes : capturingNo) = <span class="literal">true</span>;</span><br><span class="line">            CUDACHECKGOTO(cudaSetDevice(comm-&gt;cudaDev), result, failure);</span><br><span class="line">            <span class="comment">/* 在ncclLaunchPrepare里面:</span></span><br><span class="line"><span class="comment">             *      if (planner-&gt;nTasksColl == 0 &amp;&amp; planner-&gt;nTasksP2p != 0)</span></span><br><span class="line"><span class="comment">                    &#123;</span></span><br><span class="line"><span class="comment">                        NCCLCHECKGOTO(scheduleP2pTasksToPlan(comm, plan, &amp;budget), result, failure);</span></span><br><span class="line"><span class="comment">                    &#125;</span></span><br><span class="line"><span class="comment">            * 这个scheduleP2pTasksToPlan里面会把p2p的任务加入到planner里面设置了plan-&gt;kernelFn</span></span><br><span class="line"><span class="comment">            */</span></span><br><span class="line">            NCCLCHECKGOTO(ncclLaunchPrepare(comm), result, failure);</span><br><span class="line">            <span class="keyword">if</span> (useBarrier)</span><br><span class="line">                ncclCommIntraBarrierIn(comm, <span class="number">1</span>);</span><br><span class="line">            comm = comm-&gt;groupNext;</span><br><span class="line">        &#125; <span class="keyword">while</span> (comm != nullptr &amp;&amp; comm-&gt;intraComm0 == cliqueComm0);</span><br><span class="line">        cliqueNextHead = comm;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (capturingYes &amp;&amp; capturingNo)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// We have entered barriers but are aborting without leaving them. Thus</span></span><br><span class="line">            <span class="comment">// these comms are permanently trashed. We need a good mechanism for</span></span><br><span class="line">            <span class="comment">// tracking and reporting that.</span></span><br><span class="line">            WARN(<span class="string">&quot;Either none or all communicators in a ncclGroup() can be CUDA graph captured.&quot;</span>);</span><br><span class="line">            result = ncclInvalidUsage;</span><br><span class="line">            <span class="keyword">goto</span> failure;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">        &#123; <span class="comment">// Iterate rounds of launches for clique.</span></span><br><span class="line">            <span class="type">bool</span> moreRounds = <span class="literal">false</span>;</span><br><span class="line">            comm = cliqueHead;</span><br><span class="line">            <span class="keyword">do</span></span><br><span class="line">            &#123; <span class="comment">// Iterate clique members.</span></span><br><span class="line">                <span class="class"><span class="keyword">struct</span> <span class="title">ncclComm</span> *<span class="title">next</span> =</span> comm-&gt;groupNext;</span><br><span class="line">                <span class="keyword">if</span> (useBarrier)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="comment">// Barrier reduction result tells us if this was the final round.</span></span><br><span class="line">                    moreRounds = <span class="number">0</span> != ncclCommIntraBarrierOut(comm);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                &#123;</span><br><span class="line">                    moreRounds |= comm-&gt;planner.unlaunchedPlansHead != nullptr;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (moreRounds)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="comment">// Pop next unlaunched kernel</span></span><br><span class="line">                    <span class="class"><span class="keyword">struct</span> <span class="title">ncclKernelPlan</span> *<span class="title">plan</span> =</span> comm-&gt;planner.unlaunchedPlansHead;</span><br><span class="line">                    <span class="keyword">if</span> (plan != nullptr)</span><br><span class="line">                    &#123;</span><br><span class="line">                        comm-&gt;planner.unlaunchedPlansHead = plan-&gt;next;</span><br><span class="line">                        CUDACHECKGOTO(cudaSetDevice(comm-&gt;cudaDev), result, failure);</span><br><span class="line">                        NCCLCHECKGOTO(ncclLaunchKernelBefore_NoUncapturedCuda(comm, plan), result, failure);</span><br><span class="line">                        NCCLCHECKGOTO(ncclLaunchKernel(comm, plan), result, failure);</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="comment">// Barrier reduction input indicates if we require further rounds.</span></span><br><span class="line">                    <span class="keyword">if</span> (useBarrier)</span><br><span class="line">                        ncclCommIntraBarrierIn(comm, comm-&gt;planner.unlaunchedPlansHead != nullptr ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">                    <span class="keyword">if</span> (plan != nullptr)</span><br><span class="line">                    &#123;</span><br><span class="line">                        NCCLCHECKGOTO(ncclLaunchKernelAfter_NoCuda(comm, plan), result, failure);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                &#123; <span class="comment">// Final round.</span></span><br><span class="line">                    CUDACHECKGOTO(cudaSetDevice(comm-&gt;cudaDev), result, failure);</span><br><span class="line">                    NCCLCHECKGOTO(ncclLaunchFinish(comm), result, failure);</span><br><span class="line">                &#125;</span><br><span class="line">                comm = next;</span><br><span class="line">            &#125; <span class="keyword">while</span> (comm != cliqueNextHead);</span><br><span class="line">            <span class="keyword">if</span> (!moreRounds)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        cliqueHead = cliqueNextHead;</span><br><span class="line">    &#125; <span class="keyword">while</span> (cliqueHead != nullptr);</span><br><span class="line">failure:</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>enqueue.cc中</p>
<ul>
<li><strong>最后调用cuda执行kernel的时候，fn告知了线程要使用的device.h里面的什么函数</strong><div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">ncclResult_t <span class="title function_">ncclLaunchKernel</span><span class="params">(<span class="keyword">struct</span> ncclComm *comm, <span class="keyword">struct</span> ncclKernelPlan *plan)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ncclKernelPlanner</span> *<span class="title">planner</span> =</span> &amp;comm-&gt;planner;</span><br><span class="line">    <span class="type">int</span> nChannels = countOneBits(plan-&gt;channelMask);</span><br><span class="line">    <span class="type">void</span> *sym = plan-&gt;kernelFn;</span><br><span class="line">    dim3 grid = &#123;(<span class="type">unsigned</span>)nChannels, <span class="number">1</span>, <span class="number">1</span>&#125;;</span><br><span class="line">    dim3 block = &#123;(<span class="type">unsigned</span>)plan-&gt;threadPerBlock, <span class="number">1</span>, <span class="number">1</span>&#125;;</span><br><span class="line">    <span class="type">int</span> smem = ncclShmemDynamicSize(comm-&gt;cudaArch);</span><br><span class="line">    cudaStream_t launchStream = planner-&gt;streams-&gt;stream;</span><br><span class="line">    <span class="type">void</span> *extra[] = &#123;</span><br><span class="line">        CU_LAUNCH_PARAM_BUFFER_POINTER, plan-&gt;kernelArgs,</span><br><span class="line">        CU_LAUNCH_PARAM_BUFFER_SIZE, &amp;plan-&gt;kernelArgsSize,</span><br><span class="line">        CU_LAUNCH_PARAM_END&#125;;</span><br><span class="line"></span><br><span class="line">    CUfunction fn;</span><br><span class="line">    CUDACHECK(cudaGetFuncBySymbol(&amp;fn, sym));</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> CUDART_VERSION &gt;= 11080</span></span><br><span class="line">    <span class="type">int</span> driverVersion;</span><br><span class="line">    NCCLCHECK(ncclCudaDriverVersion(&amp;driverVersion));</span><br><span class="line">    <span class="keyword">if</span> (driverVersion &gt;= <span class="number">11080</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> compCap = comm-&gt;compCap;</span><br><span class="line">        <span class="type">unsigned</span> <span class="type">int</span> clusterSize = (compCap == <span class="number">90</span>) ? comm-&gt;config.cgaClusterSize : <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        CUlaunchConfig launchConfig = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">        CUlaunchAttribute launchAttrs[<span class="number">3</span>];</span><br><span class="line">        <span class="type">int</span> attrs = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">/* Cooperative Group Array (CGA)</span></span><br><span class="line"><span class="comment">         * On sm90 and later we have an extra level of hierarchy where we</span></span><br><span class="line"><span class="comment">         * can group together several blocks within the Grid, called</span></span><br><span class="line"><span class="comment">         * Thread Block Clusters.</span></span><br><span class="line"><span class="comment">         * Clusters enable multiple thread blocks running concurrently</span></span><br><span class="line"><span class="comment">         * across multiple SMs to synchronize and collaboratively fetch</span></span><br><span class="line"><span class="comment">         * and exchange data. A cluster of blocks are guaranteed to be</span></span><br><span class="line"><span class="comment">         * concurrently scheduled onto a group of SMs.</span></span><br><span class="line"><span class="comment">         * The maximum value is 8 and it must be divisible into the grid dimensions</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (clusterSize)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// Grid dimension must be divisible by clusterSize</span></span><br><span class="line">            <span class="keyword">if</span> (grid.x % clusterSize)</span><br><span class="line">                clusterSize = <span class="number">1</span>;</span><br><span class="line">            launchAttrs[attrs].id = CU_LAUNCH_ATTRIBUTE_CLUSTER_DIMENSION;</span><br><span class="line">            launchAttrs[attrs++].value.clusterDim = &#123;clusterSize, <span class="number">1</span>, <span class="number">1</span>&#125;;</span><br><span class="line">            launchAttrs[attrs].id = CU_LAUNCH_ATTRIBUTE_CLUSTER_SCHEDULING_POLICY_PREFERENCE;</span><br><span class="line">            launchAttrs[attrs++].value.clusterSchedulingPolicyPreference = CU_CLUSTER_SCHEDULING_POLICY_SPREAD;</span><br><span class="line">        &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> CUDART_VERSION &gt;= 12000</span></span><br><span class="line">        <span class="keyword">if</span> (compCap &gt;= <span class="number">90</span> &amp;&amp; driverVersion &gt;= <span class="number">12000</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// Set the NCCL Mem Sync domain on CUDA 12.0 and later (sm90)</span></span><br><span class="line">            launchAttrs[attrs].id = CU_LAUNCH_ATTRIBUTE_MEM_SYNC_DOMAIN;</span><br><span class="line">            launchAttrs[attrs++].value.memSyncDomain = (CUlaunchMemSyncDomain)ncclParamMemSyncDomain();</span><br><span class="line">        &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">        launchConfig.gridDimX = grid.x;</span><br><span class="line">        launchConfig.gridDimY = grid.y;</span><br><span class="line">        launchConfig.gridDimZ = grid.z;</span><br><span class="line">        launchConfig.blockDimX = block.x;</span><br><span class="line">        launchConfig.blockDimY = block.y;</span><br><span class="line">        launchConfig.blockDimZ = block.z;</span><br><span class="line">        launchConfig.sharedMemBytes = smem;</span><br><span class="line">        launchConfig.attrs = launchAttrs;</span><br><span class="line">        launchConfig.numAttrs = attrs;</span><br><span class="line">        launchConfig.hStream = launchStream;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// CUDACHECK(cudaLaunchKernelExC(&amp;launchConfig, fnAddr, args));</span></span><br><span class="line">        CUCHECK(cuLaunchKernelEx(&amp;launchConfig, fn, nullptr, extra));</span><br><span class="line">        <span class="keyword">return</span> ncclSuccess;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="comment">// Standard kernel launch</span></span><br><span class="line">    CUCHECK(cuLaunchKernel(fn, grid.x, grid.y, grid.z, block.x, block.y, block.z, smem, launchStream, nullptr, extra));</span><br><span class="line">    <span class="comment">// CUDACHECK(cudaLaunchKernel(fnAddr, grid, block, args, smem, launchStream));</span></span><br><span class="line">    <span class="keyword">return</span> ncclSuccess;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
</ul>
</li>
<li><p>很抽象的一个点，调用sendrecv.h里面函数的地方是一个在make之前不存在的文件，在make的时候generate.py生成了一个nccl&#x2F;build&#x2F;obj&#x2F;device&#x2F;gensrc&#x2F;sendrecv.cu，这里面使用了之前代码里声明的一个宏：</p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 原代码</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DEFINE_ncclDevKernel(suffix, coll, redop, ty, algo, proto, specializedFnId)                    \</span></span><br><span class="line"><span class="meta">    __global__ void ncclDevKernel_##suffix(ncclDevKernelArgs4K NCCL_GRID_CONSTANT const args4K)        \</span></span><br><span class="line"><span class="meta">    &#123;                                                                                                  \</span></span><br><span class="line"><span class="meta">        ncclKernelMain<span class="string">&lt;specializedFnId, RunWorkBatch&lt;coll, ty, redop&lt;ty&gt;</span>, algo, proto&gt;&gt;(&amp;args4K.args); \</span></span><br><span class="line"><span class="meta">    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DEFINE_ncclDevFunc(suffix, coll, redop, ty, algo, proto) \</span></span><br><span class="line"><span class="meta">    __device__ void ncclDevFunc_##suffix()                       \</span></span><br><span class="line"><span class="meta">    &#123;                                                            \</span></span><br><span class="line"><span class="meta">        RunWorkBatch<span class="string">&lt;coll, ty, redop&lt;ty&gt;</span>, algo, proto&gt;().run();  \</span></span><br><span class="line"><span class="meta">    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 生成的代码</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;common.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;sendrecv.h&quot;</span></span></span><br><span class="line">DEFINE_ncclDevKernel(SendRecv, ncclFuncSendRecv, FuncCopy, <span class="type">int8_t</span>, NCCL_ALGO_RING, NCCL_PROTO_SIMPLE, <span class="number">589</span>)</span><br><span class="line">DEFINE_ncclDevFunc(SendRecv, ncclFuncSendRecv, FuncCopy, <span class="type">int8_t</span>, NCCL_ALGO_RING, NCCL_PROTO_SIMPLE)</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

</li>
<li><p>ncclDevFuncRowToId也是用generate.py生成到host_table.cc里的</p>
</li>
</ul>
]]></content>
      <categories>
        <category>NCCL</category>
      </categories>
      <tags>
        <tag>NCCL</tag>
        <tag>代码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>NCCL代码阅读-02</title>
    <url>/2024/12/09/NCCL%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB-02/</url>
    <content><![CDATA[<h1 id="NCCL中重要的数据结构（持续更新）"><a href="#NCCL中重要的数据结构（持续更新）" class="headerlink" title="NCCL中重要的数据结构（持续更新）"></a>NCCL中重要的数据结构（持续更新）</h1><h2 id="struct-ncclComm"><a href="#struct-ncclComm" class="headerlink" title="struct ncclComm"></a>struct ncclComm</h2><p>实际使用的时候是</p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">ncclComm</span>* <span class="title">ncclComm_t</span>;</span></span><br></pre></td></tr></table></figure></div>
<ul>
<li>在src\nccl.h.in</li>
<li>通信上下文</li>
<li>比如两张GPU通信，每个GPU上都有一个comm，每个GPU都有一个rank，他们俩共享一个uniqueId，这个uniqueId是由root GPU生成的，然后广播给其他GPU，这样其他GPU就知道了这个通信上下文的uniqueId</li>
</ul>
<h2 id="struct-ncclInfo"><a href="#struct-ncclInfo" class="headerlink" title="struct ncclInfo"></a>struct ncclInfo</h2><ul>
<li>这个结构一直用到最后….功能很多，后面慢慢加</li>
</ul>
<h2 id="struct-ncclKernelPlanner"><a href="#struct-ncclKernelPlanner" class="headerlink" title="struct ncclKernelPlanner"></a>struct ncclKernelPlanner</h2><h1 id="NCCL代码中常用的函数和宏定义"><a href="#NCCL代码中常用的函数和宏定义" class="headerlink" title="NCCL代码中常用的函数和宏定义"></a>NCCL代码中常用的函数和宏定义</h1><h2 id="NCCLCHECK"><a href="#NCCLCHECK" class="headerlink" title="NCCLCHECK"></a>NCCLCHECK</h2><p><code>NCCLCHECK</code> 是一个宏，用于简化 NCCL 函数调用后的错误检查。在 NCCL 和许多 C&#x2F;C++ 编程环境中，错误处理通常是一个关键部分，而通过宏封装可以使代码更加简洁和易于维护。</p>
<hr>
<h3 id="NCCLCHECK-的典型定义"><a href="#NCCLCHECK-的典型定义" class="headerlink" title="NCCLCHECK 的典型定义"></a><strong>NCCLCHECK 的典型定义</strong></h3><p>在 NCCL 的代码中，<code>NCCLCHECK</code> 通常是定义为类似下面的宏：</p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> NCCLCHECK(call) do &#123; \</span></span><br><span class="line"><span class="meta">  ncclResult_t result = call; \</span></span><br><span class="line"><span class="meta">  <span class="keyword">if</span> (result != ncclSuccess) &#123; \</span></span><br><span class="line"><span class="meta">    printf(<span class="string">&quot;NCCL error at %s:%d: %s\n&quot;</span>, __FILE__, __LINE__, ncclGetErrorString(result)); \</span></span><br><span class="line"><span class="meta">    return result; \</span></span><br><span class="line"><span class="meta">  &#125; \</span></span><br><span class="line"><span class="meta">&#125; while(0)</span></span><br></pre></td></tr></table></figure></div>

<h3 id="功能"><a href="#功能" class="headerlink" title="功能"></a><strong>功能</strong></h3><ul>
<li><strong>执行函数调用并捕获返回值</strong>  <ul>
<li><code>call</code> 是需要执行的 NCCL 函数，比如 <code>ncclInit()</code> 或 <code>PtrCheck(out, &quot;GetUniqueId&quot;, &quot;out&quot;)</code>。这些函数通常返回一个类型为 <code>ncclResult_t</code> 的结果，用于指示是否成功。</li>
</ul>
</li>
</ul>
<h3 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a><strong>使用示例</strong></h3><p>在代码中，<code>NCCLCHECK</code> 的作用是捕获和处理 NCCL 函数的错误。例如：</p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">NCCLCHECK(ncclInit());</span><br></pre></td></tr></table></figure></div>

<p>等价于：</p>
<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ncclResult_t result = ncclInit();</span><br><span class="line">  <span class="keyword">if</span> (result != ncclSuccess) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;NCCL error at %s:%d: %s\n&quot;</span>, __FILE__, __LINE__, ncclGetErrorString(result));</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<hr>
<h2 id="cudaSetDevice"><a href="#cudaSetDevice" class="headerlink" title="cudaSetDevice"></a>cudaSetDevice</h2><div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">cudaError_t <span class="title function_">cudaSetDevice</span><span class="params">(<span class="type">int</span> device)</span>;</span><br></pre></td></tr></table></figure></div>
<ul>
<li>其实这并不是一个NCCL的函数，而是一个CUDA runtime的API</li>
<li>用于设置当前线程的CUDA设备(GPU)</li>
<li>就是说，我现在如果调用了cudaSetDevice(1)，那么接下来的CUDA函数调用都会在GPU 1上执行（我在操作1号设备），直到我再次对另一个设备调用cudaSetDevice</li>
</ul>
<hr>
<h2 id="cudaMalloc"><a href="#cudaMalloc" class="headerlink" title="cudaMalloc"></a>cudaMalloc</h2><div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">cudaError_t <span class="title function_">cudaMalloc</span><span class="params">(<span class="type">void</span>** devPtr, <span class="type">size_t</span> size)</span>;</span><br></pre></td></tr></table></figure></div>
<ul>
<li>为设备分配内存，这个设备就是之前用cudaSetDevice设置的设备</li>
<li>devPtr是一个指向指针的指针，指向的指针存的是分配的内存的地址</li>
<li>举例：<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// allocating and initializing device buffers</span></span><br><span class="line"><span class="type">float</span> **sendbuff = (<span class="type">float</span> **)<span class="built_in">malloc</span>(nDev * <span class="keyword">sizeof</span>(<span class="type">float</span> *));</span><br><span class="line"><span class="type">float</span> **recvbuff = (<span class="type">float</span> **)<span class="built_in">malloc</span>(nDev * <span class="keyword">sizeof</span>(<span class="type">float</span> *));</span><br><span class="line">cudaStream_t *s = (cudaStream_t *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(cudaStream_t) * nDev);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nDev; ++i)</span><br><span class="line">&#123;</span><br><span class="line">    CUDACHECK(cudaSetDevice(i));</span><br><span class="line">    CUDACHECK(cudaMalloc((<span class="type">void</span> **)sendbuff + i, size * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    CUDACHECK(cudaMalloc((<span class="type">void</span> **)recvbuff + i, size * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    CUDACHECK(cudaMemset(sendbuff[i], <span class="number">1</span>, size * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    CUDACHECK(cudaMemset(recvbuff[i], <span class="number">0</span>, size * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">    CUDACHECK(cudaStreamCreate(s + i));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
</ul>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/images/3a3ee784d1c88e46f7bd139614358f46.jpg"
                      width="50%"
                >


<h2 id="group-API"><a href="#group-API" class="headerlink" title="group API"></a>group API</h2><h3 id="1-Group-Calls-组调用-的概念"><a href="#1-Group-Calls-组调用-的概念" class="headerlink" title="1. Group Calls (组调用) 的概念"></a>1. <strong>Group Calls (组调用) 的概念</strong></h3><p><code>ncclGroupStart()</code> 和 <code>ncclGroupEnd()</code> 是 NCCL 提供的两个函数，用于将多个 NCCL 操作合并成一个操作进行执行。这些操作会在同一个 <strong>NCCL group</strong> 内顺序执行，从而减少了多次启动 NCCL 操作时的开销。通过使用组调用，NCCL 可以更高效地管理并发操作，尤其是在涉及多个 GPU 或多线程的场景下。</p>
<ul>
<li><p>**<code>ncclGroupStart()</code>**：启动一个 NCCL 操作组。所有在这个调用后到 <code>ncclGroupEnd()</code> 之前的 NCCL 操作都会被视作同一个组的一部分。</p>
</li>
<li><p>**<code>ncclGroupEnd()</code>**：结束 NCCL 操作组，并提交所有在 <code>ncclGroupStart()</code> 和 <code>ncclGroupEnd()</code> 之间的操作。调用这个函数后，NCCL 会将所有操作打包在一起，并尽可能高效地执行。</p>
</li>
</ul>
<p>下面如果不使用组调用（<code>ncclGroupStart()</code> 和 <code>ncclGroupEnd()</code>），会发生什么，执行的具体过程是怎样的。</p>
<h3 id="2-组调用作用之一：管理多个-GPU-的通信操作"><a href="#2-组调用作用之一：管理多个-GPU-的通信操作" class="headerlink" title="2. 组调用作用之一：管理多个 GPU 的通信操作"></a>2. <strong>组调用作用之一：管理多个 GPU 的通信操作</strong></h3><h4 id="示例：多个设备上的-ncclAllReduce"><a href="#示例：多个设备上的-ncclAllReduce" class="headerlink" title="示例：多个设备上的 ncclAllReduce"></a>示例：多个设备上的 <code>ncclAllReduce</code></h4><p>假设我们有多个 GPU（例如 4 个），并希望在每个 GPU 上执行相同的 NCCL 操作（例如 <code>ncclAllReduce</code>）。不使用 <code>ncclGroupStart()</code> 和 <code>ncclGroupEnd()</code> 时，你可能会在每个 GPU 上执行一次 <code>ncclAllReduce</code> 操作，每次都可能会等待前一个操作完成，这样会增加执行时间和延迟。</p>
<h5 id="使用-ncclGroupStart-和-ncclGroupEnd"><a href="#使用-ncclGroupStart-和-ncclGroupEnd" class="headerlink" title="使用 ncclGroupStart() 和 ncclGroupEnd()"></a>使用 <code>ncclGroupStart()</code> 和 <code>ncclGroupEnd()</code></h5><div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ncclGroupStart</span>();  <span class="comment">// 开始一个 NCCL 操作组</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nLocalDevs; i++) &#123;</span><br><span class="line">  <span class="built_in">ncclAllReduce</span>(..., comm[i], stream[i]);  <span class="comment">// 在多个 GPU 上执行操作</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">ncclGroupEnd</span>();  <span class="comment">// 结束并执行所有操作</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li>在这里，<code>ncclGroupStart()</code> 和 <code>ncclGroupEnd()</code> 包围了所有的 <code>ncclAllReduce</code> 调用，所有操作会被视为同一个组的一部分。</li>
<li><strong>执行顺序</strong>：NCCL 会在后台调度这些操作并行执行。每个 GPU 上的操作并不会阻塞其他操作的执行。</li>
<li><strong>性能</strong>：所有 GPU 上的 <code>ncclAllReduce</code> 操作可以并行执行，减少了同步和启动开销。</li>
</ul>
<h5 id="不使用-ncclGroupStart-和-ncclGroupEnd"><a href="#不使用-ncclGroupStart-和-ncclGroupEnd" class="headerlink" title="不使用 ncclGroupStart() 和 ncclGroupEnd()"></a>不使用 <code>ncclGroupStart()</code> 和 <code>ncclGroupEnd()</code></h5><div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nLocalDevs; i++) &#123;</span><br><span class="line">  <span class="built_in">ncclAllReduce</span>(..., comm[i], stream[i]);  <span class="comment">// 在多个 GPU 上执行操作</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li><p><strong>执行顺序</strong>：如果不使用组调用，NCCL 会逐个执行这些 <code>ncclAllReduce</code> 操作，<strong>等待每个操作完成后再执行下一个操作</strong>。</p>
<ul>
<li>比如，假设有 4 个 GPU，<code>ncclAllReduce</code> 操作会依次执行，每次执行时都会等待前一个操作完成，然后才会开始下一个操作。这种顺序执行会导致明显的延迟。</li>
</ul>
</li>
<li><p><strong>死锁风险</strong>：如果在每个操作中都需要同步，且这些操作依赖于其他线程&#x2F;进程的结果，可能会导致死锁或不必要的阻塞。例如，<code>ncclAllReduce</code> 在每个设备上执行时，可能需要等待所有设备的操作完成。如果按代码顺序挨个执行（其实就是阻塞），那后一个操作必须等前一个做完才能进行，但实际上，他俩应该同时执行。</p>
</li>
</ul>
<h3 id="3-组调用作用之二：在创建通信器时使用-Group-Calls"><a href="#3-组调用作用之二：在创建通信器时使用-Group-Calls" class="headerlink" title="3. 组调用作用之二：在创建通信器时使用 Group Calls"></a>3. <strong>组调用作用之二：在创建通信器时使用 Group Calls</strong></h3><h4 id="示例：在一个线程中管理多个-GPU"><a href="#示例：在一个线程中管理多个-GPU" class="headerlink" title="示例：在一个线程中管理多个 GPU"></a>示例：在一个线程中管理多个 GPU</h4><p>假设你有一个线程需要初始化多个 GPU 上的 NCCL 通信器。初始化操作（如 <code>ncclCommInitRank</code>）通常是一个阻塞操作，如果不使用 <code>ncclGroupStart()</code> 和 <code>ncclGroupEnd()</code>，这些初始化操作会依次执行，每次操作都必须等待前一个操作完成，这可能会浪费时间。</p>
<h5 id="使用-ncclGroupStart-和-ncclGroupEnd-1"><a href="#使用-ncclGroupStart-和-ncclGroupEnd-1" class="headerlink" title="使用 ncclGroupStart() 和 ncclGroupEnd()"></a>使用 <code>ncclGroupStart()</code> 和 <code>ncclGroupEnd()</code></h5><div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ncclGroupStart</span>();  <span class="comment">// 开始一个 NCCL 操作组</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nLocalDevs; i++) &#123;</span><br><span class="line">  <span class="built_in">cudaSetDevice</span>(device[i]);  <span class="comment">// 设置当前 GPU</span></span><br><span class="line">  <span class="built_in">ncclCommInitRank</span>(comms + i, nranks, commId, rank[i]);  <span class="comment">// 初始化通信器</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">ncclGroupEnd</span>();  <span class="comment">// 结束并执行所有操作</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li><strong>执行顺序</strong>：<code>ncclCommInitRank</code> 调用会并行地在每个 GPU 上执行。</li>
<li><strong>性能</strong>：因为通信器的初始化操作是通过组调用来管理的，NCCL 可以在后台并行处理所有设备的初始化操作，而不是一个接一个地执行。这减少了初始化的时间。</li>
</ul>
<h5 id="不使用-ncclGroupStart-和-ncclGroupEnd-1"><a href="#不使用-ncclGroupStart-和-ncclGroupEnd-1" class="headerlink" title="不使用 ncclGroupStart() 和 ncclGroupEnd()"></a>不使用 <code>ncclGroupStart()</code> 和 <code>ncclGroupEnd()</code></h5><div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nLocalDevs; i++) &#123;</span><br><span class="line">  <span class="built_in">cudaSetDevice</span>(device[i]);  <span class="comment">// 设置当前 GPU</span></span><br><span class="line">  <span class="built_in">ncclCommInitRank</span>(comms + i, nranks, commId, rank[i]);  <span class="comment">// 初始化通信器</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<ul>
<li><strong>执行顺序</strong>：<code>ncclCommInitRank</code> 会按顺序执行，等待每个设备的初始化完成后再继续执行下一个设备的初始化。</li>
<li><strong>性能</strong>：没有组调用，通信器初始化会串行执行，导致设备初始化时间更长。如果有多个 GPU，这会浪费很多时间在设备间的同步和等待上。</li>
</ul>
<h3 id="3-组调用作用之三：聚合通信操作"><a href="#3-组调用作用之三：聚合通信操作" class="headerlink" title="3. 组调用作用之三：聚合通信操作"></a>3. <strong>组调用作用之三：聚合通信操作</strong></h3><h4 id="示例：多个集体操作（ncclBroadcast-和-ncclAllReduce）聚合"><a href="#示例：多个集体操作（ncclBroadcast-和-ncclAllReduce）聚合" class="headerlink" title="示例：多个集体操作（ncclBroadcast 和 ncclAllReduce）聚合"></a>示例：多个集体操作（<code>ncclBroadcast</code> 和 <code>ncclAllReduce</code>）聚合</h4><p>假设你想在多个 GPU 上执行多个不同的 NCCL 集体操作（例如，一个 <code>ncclBroadcast</code> 和两个 <code>ncclAllReduce</code>）。如果不使用组调用，NCCL 会为每个操作单独启动一次通信。</p>
<h5 id="使用-ncclGroupStart-和-ncclGroupEnd-2"><a href="#使用-ncclGroupStart-和-ncclGroupEnd-2" class="headerlink" title="使用 ncclGroupStart() 和 ncclGroupEnd()"></a>使用 <code>ncclGroupStart()</code> 和 <code>ncclGroupEnd()</code></h5><div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ncclGroupStart</span>();  <span class="comment">// 开始 NCCL 操作组</span></span><br><span class="line"><span class="built_in">ncclBroadcast</span>(sendbuff1, recvbuff1, count1, datatype, root, comm, stream);</span><br><span class="line"><span class="built_in">ncclAllReduce</span>(sendbuff2, recvbuff2, count2, datatype, comm, stream);</span><br><span class="line"><span class="built_in">ncclAllReduce</span>(sendbuff3, recvbuff3, count3, datatype, comm, stream);</span><br><span class="line"><span class="built_in">ncclGroupEnd</span>();  <span class="comment">// 结束并执行所有操作</span></span><br></pre></td></tr></table></figure></div>

<ul>
<li><strong>执行顺序</strong>：所有的集体操作（<code>ncclBroadcast</code> 和 <code>ncclAllReduce</code>）会被合并到一个组中执行。NCCL 会将这些操作作为一个批次提交，减少了每个操作单独启动时的开销。</li>
<li><strong>性能</strong>：通过将多个操作合并成一个组，NCCL 只需要发起一次通信并等待完成，从而减少了启动和同步的延迟。</li>
</ul>
<h5 id="不使用-ncclGroupStart-和-ncclGroupEnd-2"><a href="#不使用-ncclGroupStart-和-ncclGroupEnd-2" class="headerlink" title="不使用 ncclGroupStart() 和 ncclGroupEnd()"></a>不使用 <code>ncclGroupStart()</code> 和 <code>ncclGroupEnd()</code></h5><div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ncclBroadcast</span>(sendbuff1, recvbuff1, count1, datatype, root, comm, stream);</span><br><span class="line"><span class="built_in">ncclAllReduce</span>(sendbuff2, recvbuff2, count2, datatype, comm, stream);</span><br><span class="line"><span class="built_in">ncclAllReduce</span>(sendbuff3, recvbuff3, count3, datatype, comm, stream);</span><br></pre></td></tr></table></figure></div>

<ul>
<li><strong>执行顺序</strong>：每个 <code>ncclBroadcast</code> 和 <code>ncclAllReduce</code> 操作都会单独执行，NCCL 会依次启动每个操作并等待前一个操作完成。这样，可能会在每个操作之间产生额外的延迟，尤其是在启动多个 NCCL 操作时。</li>
<li><strong>性能</strong>：每个操作都会带来额外的启动开销，导致总体性能下降。</li>
</ul>
<h3 id="4-额外补充：阻塞组和非阻塞组"><a href="#4-额外补充：阻塞组和非阻塞组" class="headerlink" title="4. 额外补充：阻塞组和非阻塞组"></a>4. <strong>额外补充：阻塞组和非阻塞组</strong></h3><h4 id="阻塞组（Blocking-Group）"><a href="#阻塞组（Blocking-Group）" class="headerlink" title="阻塞组（Blocking Group）"></a><strong>阻塞组（Blocking Group）</strong></h4><p><strong>阻塞组</strong>意味着当调用 <code>ncclGroupEnd()</code> 时，NCCL 会<strong>等待</strong>所有在 <code>ncclGroupStart()</code> 和 <code>ncclGroupEnd()</code> 之间的 NCCL 操作完全完成（包括启动、执行和同步）。在这种模式下，<code>ncclGroupEnd()</code> 会在所有操作完成后返回，意味着直到所有操作完成，你才能继续执行后续的代码。</p>
<h5 id="阻塞组的特点："><a href="#阻塞组的特点：" class="headerlink" title="阻塞组的特点："></a>阻塞组的特点：</h5><ul>
<li>所有组中的 NCCL 操作会按顺序依次发起并等待完成。</li>
<li><code>ncclGroupEnd()</code> 会<strong>阻塞</strong>直到所有 NCCL 操作都完成。</li>
<li>阻塞组适用于你希望在继续执行其他任务之前等待所有 NCCL 操作完成的场景。</li>
</ul>
<p><strong>示例</strong>：</p>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ncclGroupStart</span>();  <span class="comment">// 开始一个 NCCL 操作组</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nLocalDevs; i++) &#123;</span><br><span class="line">  <span class="built_in">ncclAllReduce</span>(..., comm[i], stream[i]);  <span class="comment">// 在多个 GPU 上执行操作</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">ncclGroupEnd</span>();  <span class="comment">// 等待所有操作完成</span></span><br></pre></td></tr></table></figure></div>

<p>在这个例子中，<code>ncclGroupEnd()</code> 会阻塞，直到所有的 <code>ncclAllReduce</code> 操作完成。这样可以确保在 <code>ncclGroupEnd()</code> 返回之前，所有的 NCCL 操作都已经被提交和执行。</p>
<h4 id="2-非阻塞组（Non-blocking-Group）"><a href="#2-非阻塞组（Non-blocking-Group）" class="headerlink" title="2. 非阻塞组（Non-blocking Group）"></a>2. <strong>非阻塞组（Non-blocking Group）</strong></h4><p><strong>非阻塞组</strong>指的是当你调用 <code>ncclGroupEnd()</code> 时，NCCL 并不会阻塞直到所有操作完成。相反，<code>ncclGroupEnd()</code> 会尽快返回，并表示操作组已被提交，但后台的 NCCL 操作可能仍在执行中。这种模式允许你执行其他任务，同时在后台继续完成 NCCL 操作。</p>
<ul>
<li><strong>非阻塞组</strong>的核心是当 <code>ncclGroupEnd()</code> 返回时，NCCL 操作可能仍在后台执行。这时你可以检查操作是否完成（通过查看返回状态或使用异步错误检查），而不是等待它们同步完成。</li>
<li>非阻塞组适用于你希望进行并行操作或不希望阻塞主线程的场景，例如，你希望继续执行其他计算或通信操作，而不是等待每个 NCCL 操作完成。</li>
</ul>
<h5 id="非阻塞组的特点："><a href="#非阻塞组的特点：" class="headerlink" title="非阻塞组的特点："></a>非阻塞组的特点：</h5><ul>
<li><code>ncclGroupEnd()</code> 会尽快返回，不会等待所有操作完成。</li>
<li>当组中的操作还在后台执行时，<code>ncclGroupEnd()</code> 会返回 <code>ncclInProgress</code>，表示操作仍在进行。</li>
<li>你可以通过调用 <code>ncclCommGetAsyncError()</code> 来检查操作的状态，以便确认 NCCL 操作是否完成。</li>
<li>如果使用非阻塞组，通常需要在后续代码中进行同步（如调用 <code>cudaStreamSynchronize()</code>）来确保所有操作完成。</li>
</ul>
<p><strong>示例</strong>：</p>
<div class="code-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ncclGroupStart</span>();  <span class="comment">// 开始一个 NCCL 操作组</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nLocalDevs; i++) &#123;</span><br><span class="line">  <span class="built_in">ncclAllReduce</span>(..., comm[i], stream[i]);  <span class="comment">// 在多个 GPU 上执行操作</span></span><br><span class="line">&#125;</span><br><span class="line">ret = <span class="built_in">ncclGroupEnd</span>();  <span class="comment">// 不等待所有操作完成，尽快返回</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 非阻塞操作完成时的处理</span></span><br><span class="line"><span class="keyword">if</span> (ret == ncclInProgress) &#123;</span><br><span class="line">  <span class="comment">// 检查操作是否完成</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nLocalDevs; i++) &#123;</span><br><span class="line">    <span class="built_in">ncclCommGetAsyncError</span>(comm[i], &amp;state);</span><br><span class="line">    <span class="keyword">while</span> (state == ncclInProgress) &#123;</span><br><span class="line">      <span class="comment">// 等待操作完成</span></span><br><span class="line">      <span class="built_in">ncclCommGetAsyncError</span>(comm[i], &amp;state);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>在这个例子中，<code>ncclGroupEnd()</code> 会尽快返回，并可能返回 <code>ncclInProgress</code>，表示 NCCL 操作仍在后台进行。你可以通过调用 <code>ncclCommGetAsyncError()</code> 来轮询每个操作的状态，并在操作完成时继续执行后续代码。</p>
]]></content>
      <categories>
        <category>NCCL</category>
      </categories>
      <tags>
        <tag>NCCL</tag>
        <tag>代码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo常用命令</title>
    <url>/2024/12/04/hexo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h2 id="新建一篇文章"><a href="#新建一篇文章" class="headerlink" title="新建一篇文章"></a>新建一篇文章</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new <span class="string">&quot;文章标题&quot;</span></span><br></pre></td></tr></table></figure></div>

<h2 id="本地重新生成静态文件"><a href="#本地重新生成静态文件" class="headerlink" title="本地重新生成静态文件"></a>本地重新生成静态文件</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br></pre></td></tr></table></figure></div>

<h2 id="发布到github-io"><a href="#发布到github-io" class="headerlink" title="发布到github.io"></a>发布到github.io</h2><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure></div>

<h2 id="在文章里面插入图片"><a href="#在文章里面插入图片" class="headerlink" title="在文章里面插入图片"></a>在文章里面插入图片</h2><ul>
<li>首先把图片放到source&#x2F;images下面</li>
<li>然后文章里插入：<div class="code-container" data-rel="Markdown"><figure class="iseeu highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;/images/图片文件名&quot;</span> <span class="attr">width</span>=<span class="string">&quot;50%&quot;</span>&gt;</span></span></span><br></pre></td></tr></table></figure></div></li>
</ul>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>部署</tag>
      </tags>
  </entry>
  <entry>
    <title>NCCL代码阅读-03</title>
    <url>/2024/12/09/NCCL%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB-03/</url>
    <content><![CDATA[<h2 id="通信组创建和销毁-官网给的例子，解释看注释"><a href="#通信组创建和销毁-官网给的例子，解释看注释" class="headerlink" title="通信组创建和销毁(官网给的例子，解释看注释)"></a>通信组创建和销毁(官网给的例子，解释看注释)</h2><h3 id="一个进程，一个线程，多个设备"><a href="#一个进程，一个线程，多个设备" class="headerlink" title="一个进程，一个线程，多个设备"></a>一个进程，一个线程，多个设备</h3><ul>
<li>在这种单进程的场景下，可以使用ncclCommInitAll()<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span><br><span class="line">&#123;</span><br><span class="line">    ncclComm_t comms[<span class="number">4</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// managing 4 devices</span></span><br><span class="line">    <span class="type">int</span> nDev = <span class="number">4</span>;</span><br><span class="line">    <span class="type">int</span> size = <span class="number">32</span> * <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line">    <span class="type">int</span> devs[<span class="number">4</span>] = &#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这部分的解释见《NCCL代码阅读-02》的cudaAlloc部分</span></span><br><span class="line">    <span class="comment">// allocating and initializing device buffers</span></span><br><span class="line">    <span class="type">float</span> **sendbuff = (<span class="type">float</span> **)<span class="built_in">malloc</span>(nDev * <span class="keyword">sizeof</span>(<span class="type">float</span> *));</span><br><span class="line">    <span class="type">float</span> **recvbuff = (<span class="type">float</span> **)<span class="built_in">malloc</span>(nDev * <span class="keyword">sizeof</span>(<span class="type">float</span> *));</span><br><span class="line">    cudaStream_t *s = (cudaStream_t *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(cudaStream_t) * nDev);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nDev; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        CUDACHECK(cudaSetDevice(i));</span><br><span class="line">        CUDACHECK(cudaMalloc((<span class="type">void</span> **)sendbuff + i, size * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">        CUDACHECK(cudaMalloc((<span class="type">void</span> **)recvbuff + i, size * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">        CUDACHECK(cudaMemset(sendbuff[i], <span class="number">1</span>, size * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">        CUDACHECK(cudaMemset(recvbuff[i], <span class="number">0</span>, size * <span class="keyword">sizeof</span>(<span class="type">float</span>)));</span><br><span class="line">        CUDACHECK(cudaStreamCreate(s + i));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// initializing NCCL</span></span><br><span class="line">    NCCLCHECK(ncclCommInitAll(comms, nDev, devs));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// calling NCCL communication API. Group API is required when using</span></span><br><span class="line">    <span class="comment">// multiple devices per thread</span></span><br><span class="line">    <span class="comment">// 单线程控制多个GPU时必须要用group API，否则会死锁</span></span><br><span class="line">    NCCLCHECK(ncclGroupStart());</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nDev; ++i)</span><br><span class="line">        NCCLCHECK(ncclAllReduce((<span class="type">const</span> <span class="type">void</span> *)sendbuff[i], (<span class="type">void</span> *)recvbuff[i], size, ncclFloat, ncclSum,</span><br><span class="line">                                comms[i], s[i]));</span><br><span class="line">    NCCLCHECK(ncclGroupEnd());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// synchronizing on CUDA streams to wait for completion of NCCL operation</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nDev; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        CUDACHECK(cudaSetDevice(i));</span><br><span class="line">        CUDACHECK(cudaStreamSynchronize(s[i]));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// free device buffers</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nDev; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        CUDACHECK(cudaSetDevice(i));</span><br><span class="line">        CUDACHECK(cudaFree(sendbuff[i]));</span><br><span class="line">        CUDACHECK(cudaFree(recvbuff[i]));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// finalizing NCCL</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nDev; ++i)</span><br><span class="line">        ncclCommDestroy(comms[i]);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Success \n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
</ul>
<h2 id="一个具体的调用路径：sendrecv操作"><a href="#一个具体的调用路径：sendrecv操作" class="headerlink" title="一个具体的调用路径：sendrecv操作"></a>一个具体的调用路径：sendrecv操作</h2><ul>
<li>不得不说nccl的调用真是够复杂的……</li>
<li>我们就从nccl-test（官方给的测试代码）入手，看看sendrecv这个最简单的操作是怎么做的</li>
</ul>
<h3 id="SendRecvRunColl"><a href="#SendRecvRunColl" class="headerlink" title="SendRecvRunColl"></a>SendRecvRunColl</h3><ul>
<li>这个函数是nccl-test里面的一个测试函数，用于测试sendrecv操作<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">testResult_t <span class="title function_">SendRecvRunColl</span><span class="params">(<span class="type">void</span> *sendbuff, <span class="type">void</span> *recvbuff, <span class="type">size_t</span> count, ncclDataType_t type, ncclRedOp_t op, <span class="type">int</span> root, ncclComm_t comm, cudaStream_t stream)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> nRanks;</span><br><span class="line">    NCCLCHECK(ncclCommCount(comm, &amp;nRanks));</span><br><span class="line">    <span class="type">int</span> rank;</span><br><span class="line">    NCCLCHECK(ncclCommUserRank(comm, &amp;rank));</span><br><span class="line">    <span class="type">int</span> recvPeer = (rank - <span class="number">1</span> + nRanks) % nRanks;</span><br><span class="line">    <span class="type">int</span> sendPeer = (rank + <span class="number">1</span>) % nRanks;</span><br><span class="line"></span><br><span class="line">    NCCLCHECK(ncclGroupStart());</span><br><span class="line">    NCCLCHECK(ncclSend(sendbuff, count, type, sendPeer, comm, stream));</span><br><span class="line">    NCCLCHECK(ncclRecv(recvbuff, count, type, recvPeer, comm, stream));</span><br><span class="line">    NCCLCHECK(ncclGroupEnd());</span><br><span class="line">    <span class="keyword">return</span> testSuccess;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
<li>这里可以很明显的看到，接收方和发送方，都要显式调用一次操作，ncclSend和ncclRecv</li>
<li>ncclSend和ncclRecv被包裹在了ncclGroupStart和ncclGroupEnd里面</li>
</ul>
<h3 id="ncclSend和ncclRecv（以ncclSend为例）"><a href="#ncclSend和ncclRecv（以ncclSend为例）" class="headerlink" title="ncclSend和ncclRecv（以ncclSend为例）"></a>ncclSend和ncclRecv（以ncclSend为例）</h3><div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">ncclResult_t <span class="title function_">ncclSend</span><span class="params">(<span class="type">const</span> <span class="type">void</span> *sendbuff, <span class="type">size_t</span> count, ncclDataType_t datatype, <span class="type">int</span> peer,</span></span><br><span class="line"><span class="params">                      ncclComm_t comm, cudaStream_t stream)</span></span><br><span class="line">&#123;</span><br><span class="line">    NvtxParamsSendRecv payload&#123;count * <span class="title function_">ncclTypeSize</span><span class="params">(datatype)</span>, peer&#125;;</span><br><span class="line">    NVTX3_FUNC_WITH_PARAMS(Send, SendRecvSchema, payload)</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ncclInfo</span> <span class="title">info</span> =</span> &#123;ncclFuncSend, <span class="string">&quot;Send&quot;</span>,</span><br><span class="line">                            <span class="literal">NULL</span>, (<span class="type">void</span> *)sendbuff, count, datatype, ncclSum, peer, comm, stream, <span class="comment">/* Args */</span></span><br><span class="line">                            <span class="number">1</span>, <span class="number">1</span>&#125;;</span><br><span class="line">    ncclResult_t ret;</span><br><span class="line">    NCCLCHECK(ncclGroupStart());</span><br><span class="line">    NCCLCHECKGOTO(ncclEnqueueCheck(&amp;info), ret, <span class="built_in">exit</span>);</span><br><span class="line"><span class="built_in">exit</span>:</span><br><span class="line">    NCCLCHECK(ncclGroupEnd());</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<ul>
<li>这边可以看到，在ncclSend里面有一个很重要的数据结构<strong>ncclInfo</strong>，这个结构体里面包含了这次通信的所有信息，其中<strong>操作种类</strong>是被第一个参数传进去的，ncclInfo这个数据结构的介绍见《NCCL代码阅读-02》</li>
</ul>
<h3 id="ncclEnqueueCheck"><a href="#ncclEnqueueCheck" class="headerlink" title="ncclEnqueueCheck"></a>ncclEnqueueCheck</h3><div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">ncclResult_t <span class="title function_">ncclEnqueueCheck</span><span class="params">(<span class="keyword">struct</span> ncclInfo *info)</span></span><br><span class="line">&#123;</span><br><span class="line">    NCCLCHECK(ncclGroupStartInternal());</span><br><span class="line">    ncclResult_t ret = ncclSuccess;</span><br><span class="line">    <span class="type">int</span> devOld = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    NCCLCHECKGOTO(CommCheck(info-&gt;comm, info-&gt;opName, <span class="string">&quot;comm&quot;</span>), ret, fail);</span><br><span class="line">    <span class="comment">// Check whether communicator is ready to communicate</span></span><br><span class="line">    NCCLCHECKGOTO(ncclCommEnsureReady(info-&gt;comm), ret, fail);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (info-&gt;comm-&gt;checkPointers)</span><br><span class="line">    &#123;</span><br><span class="line">        CUDACHECKGOTO(cudaGetDevice(&amp;devOld), ret, fail);</span><br><span class="line">        CUDACHECKGOTO(cudaSetDevice(info-&gt;comm-&gt;cudaDev), ret, fail);</span><br><span class="line">    &#125;</span><br><span class="line">    NCCLCHECKGOTO(ArgsCheck(info), ret, fail);</span><br><span class="line"></span><br><span class="line">    INFO(NCCL_COLL, <span class="string">&quot;%s: opCount %lx sendbuff %p recvbuff %p count %zu datatype %d op %d root %d comm %p [nranks=%d] stream %p&quot;</span>,</span><br><span class="line">         info-&gt;opName, info-&gt;comm-&gt;opCount, info-&gt;sendbuff, info-&gt;recvbuff, info-&gt;count,</span><br><span class="line">         info-&gt;datatype, info-&gt;op, info-&gt;root, info-&gt;comm, info-&gt;comm-&gt;nRanks, info-&gt;stream);</span><br><span class="line">    TRACE_CALL(<span class="string">&quot;nccl%s(%&quot;</span> PRIx64 <span class="string">&quot;,%&quot;</span> PRIx64 <span class="string">&quot;,%zu,%d,%d,%d,%p,%p)&quot;</span>, info-&gt;opName, reinterpret_cast&lt;<span class="type">int64_t</span>&gt;(info-&gt;sendbuff), reinterpret_cast&lt;<span class="type">int64_t</span>&gt;(info-&gt;recvbuff), info-&gt;count, info-&gt;datatype, info-&gt;op, info-&gt;root, info-&gt;comm, info-&gt;stream);</span><br><span class="line"></span><br><span class="line">    NCCLCHECKGOTO(taskAppend(info-&gt;comm, info), ret, fail);</span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span>:</span><br><span class="line">    <span class="keyword">if</span> (devOld != <span class="number">-1</span>)</span><br><span class="line">        CUDACHECK(cudaSetDevice(devOld));</span><br><span class="line">    ncclGroupErrCheck(ret);</span><br><span class="line">    NCCLCHECK(ncclGroupEndInternal());</span><br><span class="line">    <span class="comment">/* if depth is 1, ncclGroupEndInternal() will trigger group ops. The state can change</span></span><br><span class="line"><span class="comment">     * so we have to check state here. */</span></span><br><span class="line">    <span class="keyword">if</span> (info-&gt;comm &amp;&amp; !info-&gt;comm-&gt;config.blocking)</span><br><span class="line">    &#123;</span><br><span class="line">        NCCLCHECK(ncclCommGetAsyncError(info-&gt;comm, &amp;ret));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">fail:</span><br><span class="line">    <span class="keyword">if</span> (info-&gt;comm &amp;&amp; !info-&gt;comm-&gt;config.blocking)</span><br><span class="line">        (<span class="type">void</span>)ncclCommSetAsyncError(info-&gt;comm, ret);</span><br><span class="line">    <span class="keyword">goto</span> <span class="built_in">exit</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<ul>
<li>前面就是做了一些入队的检查，真正进行入队操作的是<strong>taskAppend</strong>函数</li>
<li>taskAppend函数将info转换成了一个task，并且将这个task放入对应comm的comm-&gt;planner中，这个planner，即ncclKernelPlanner，是一个比较复杂的数据结构，简要来说就是一个comm上任务的调度器，这个数据结构的介绍后续会放入《NCCL代码阅读-02》</li>
<li>在<strong>ncclGroupEndInternal</strong>里面，调用了<strong>groupLaunch</strong>，<strong>groupLaunch</strong>中的<strong>doLaunches</strong>调用了**ncclLaunchKernel(comm, plan)**，这个函数就是真正的调用CUDA kernel的地方</li>
</ul>
<h3 id="ncclLaunchKernel"><a href="#ncclLaunchKernel" class="headerlink" title="ncclLaunchKernel"></a>ncclLaunchKernel</h3><div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">ncclResult_t <span class="title function_">ncclLaunchKernel</span><span class="params">(<span class="keyword">struct</span> ncclComm *comm, <span class="keyword">struct</span> ncclKernelPlan *plan)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ncclKernelPlanner</span> *<span class="title">planner</span> =</span> &amp;comm-&gt;planner;</span><br><span class="line">    <span class="type">int</span> nChannels = countOneBits(plan-&gt;channelMask);</span><br><span class="line">    <span class="type">void</span> *sym = plan-&gt;kernelFn;</span><br><span class="line">    dim3 grid = &#123;(<span class="type">unsigned</span>)nChannels, <span class="number">1</span>, <span class="number">1</span>&#125;;</span><br><span class="line">    dim3 block = &#123;(<span class="type">unsigned</span>)plan-&gt;threadPerBlock, <span class="number">1</span>, <span class="number">1</span>&#125;;</span><br><span class="line">    <span class="type">int</span> smem = ncclShmemDynamicSize(comm-&gt;cudaArch);</span><br><span class="line">    cudaStream_t launchStream = planner-&gt;streams-&gt;stream;</span><br><span class="line">    <span class="type">void</span> *extra[] = &#123;</span><br><span class="line">        CU_LAUNCH_PARAM_BUFFER_POINTER, plan-&gt;kernelArgs,</span><br><span class="line">        CU_LAUNCH_PARAM_BUFFER_SIZE, &amp;plan-&gt;kernelArgsSize,</span><br><span class="line">        CU_LAUNCH_PARAM_END&#125;;</span><br><span class="line"></span><br><span class="line">    CUfunction fn;</span><br><span class="line">    CUDACHECK(cudaGetFuncBySymbol(&amp;fn, sym));</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> CUDART_VERSION &gt;= 11080</span></span><br><span class="line">    <span class="type">int</span> driverVersion;</span><br><span class="line">    NCCLCHECK(ncclCudaDriverVersion(&amp;driverVersion));</span><br><span class="line">    <span class="keyword">if</span> (driverVersion &gt;= <span class="number">11080</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> compCap = comm-&gt;compCap;</span><br><span class="line">        <span class="type">unsigned</span> <span class="type">int</span> clusterSize = (compCap == <span class="number">90</span>) ? comm-&gt;config.cgaClusterSize : <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        CUlaunchConfig launchConfig = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">        CUlaunchAttribute launchAttrs[<span class="number">3</span>];</span><br><span class="line">        <span class="type">int</span> attrs = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">/* Cooperative Group Array (CGA)</span></span><br><span class="line"><span class="comment">         * On sm90 and later we have an extra level of hierarchy where we</span></span><br><span class="line"><span class="comment">         * can group together several blocks within the Grid, called</span></span><br><span class="line"><span class="comment">         * Thread Block Clusters.</span></span><br><span class="line"><span class="comment">         * Clusters enable multiple thread blocks running concurrently</span></span><br><span class="line"><span class="comment">         * across multiple SMs to synchronize and collaboratively fetch</span></span><br><span class="line"><span class="comment">         * and exchange data. A cluster of blocks are guaranteed to be</span></span><br><span class="line"><span class="comment">         * concurrently scheduled onto a group of SMs.</span></span><br><span class="line"><span class="comment">         * The maximum value is 8 and it must be divisible into the grid dimensions</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (clusterSize)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// Grid dimension must be divisible by clusterSize</span></span><br><span class="line">            <span class="keyword">if</span> (grid.x % clusterSize)</span><br><span class="line">                clusterSize = <span class="number">1</span>;</span><br><span class="line">            launchAttrs[attrs].id = CU_LAUNCH_ATTRIBUTE_CLUSTER_DIMENSION;</span><br><span class="line">            launchAttrs[attrs++].value.clusterDim = &#123;clusterSize, <span class="number">1</span>, <span class="number">1</span>&#125;;</span><br><span class="line">            launchAttrs[attrs].id = CU_LAUNCH_ATTRIBUTE_CLUSTER_SCHEDULING_POLICY_PREFERENCE;</span><br><span class="line">            launchAttrs[attrs++].value.clusterSchedulingPolicyPreference = CU_CLUSTER_SCHEDULING_POLICY_SPREAD;</span><br><span class="line">        &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> CUDART_VERSION &gt;= 12000</span></span><br><span class="line">        <span class="keyword">if</span> (compCap &gt;= <span class="number">90</span> &amp;&amp; driverVersion &gt;= <span class="number">12000</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// Set the NCCL Mem Sync domain on CUDA 12.0 and later (sm90)</span></span><br><span class="line">            launchAttrs[attrs].id = CU_LAUNCH_ATTRIBUTE_MEM_SYNC_DOMAIN;</span><br><span class="line">            launchAttrs[attrs++].value.memSyncDomain = (CUlaunchMemSyncDomain)ncclParamMemSyncDomain();</span><br><span class="line">        &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">        launchConfig.gridDimX = grid.x;</span><br><span class="line">        launchConfig.gridDimY = grid.y;</span><br><span class="line">        launchConfig.gridDimZ = grid.z;</span><br><span class="line">        launchConfig.blockDimX = block.x;</span><br><span class="line">        launchConfig.blockDimY = block.y;</span><br><span class="line">        launchConfig.blockDimZ = block.z;</span><br><span class="line">        launchConfig.sharedMemBytes = smem;</span><br><span class="line">        launchConfig.attrs = launchAttrs;</span><br><span class="line">        launchConfig.numAttrs = attrs;</span><br><span class="line">        launchConfig.hStream = launchStream;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// CUDACHECK(cudaLaunchKernelExC(&amp;launchConfig, fnAddr, args));</span></span><br><span class="line">        CUCHECK(cuLaunchKernelEx(&amp;launchConfig, fn, nullptr, extra));</span><br><span class="line">        <span class="keyword">return</span> ncclSuccess;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="comment">// Standard kernel launch</span></span><br><span class="line">    CUCHECK(cuLaunchKernel(fn, grid.x, grid.y, grid.z, block.x, block.y, block.z, smem, launchStream, nullptr, extra));</span><br><span class="line">    <span class="comment">// CUDACHECK(cudaLaunchKernel(fnAddr, grid, block, args, smem, launchStream));</span></span><br><span class="line">    <span class="keyword">return</span> ncclSuccess;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<ul>
<li>这里面最后调用的是cuLaunchKernel，其中fn是通过cudaGetFuncBySymbol获取的，这个symbol就是nccl的kernel函数</li>
<li>这个sym来自plan-&gt;kernelFn，它在<strong>scheduleP2pTasksToPlan</strong>中被赋值:<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (!plan-&gt;kernelSpecialized)</span><br><span class="line">&#123;</span><br><span class="line">    plan-&gt;kernelFn = ncclDevKernelForFunc[ncclDevFuncId_P2p()];</span><br><span class="line">    plan-&gt;kernelSpecialized = ncclDevKernelForFuncIsSpecialized[ncclDevFuncId_P2p()];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></li>
<li>其中ncclDevFunId_P2p()是这样的：<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="type">int</span> <span class="title function_">ncclDevFuncId_P2p</span><span class="params">()</span> &#123; <span class="keyword">return</span> ncclDevFuncRowToId[<span class="number">0</span>]; &#125;</span><br></pre></td></tr></table></figure></div></li>
<li>这个ncclDevFuncRowToId是一个映射表，填写这个映射表的位置还挺难找，在nccl&#x2F;src&#x2F;device&#x2F;下面，有一个<strong>generate.py</strong>，会在build里面生成一个nccl&#x2F;build&#x2F;obj&#x2F;device&#x2F;gensrc&#x2F;host_table.cc</li>
<li>那CUDA是怎么通过fn去找到对应的kernel函数的呢？我们仍然要看generate.py，这个脚本还会生成一组文件，其中一个是nccl&#x2F;build&#x2F;obj&#x2F;device&#x2F;gensrc&#x2F;sendrecv.cu，这里面的内容是这样的：<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;common.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;sendrecv.h&quot;</span></span></span><br><span class="line">DEFINE_ncclDevKernel(SendRecv, ncclFuncSendRecv, FuncCopy, <span class="type">int8_t</span>, NCCL_ALGO_RING, NCCL_PROTO_SIMPLE, <span class="number">589</span>)</span><br><span class="line">DEFINE_ncclDevFunc(SendRecv, ncclFuncSendRecv, FuncCopy, <span class="type">int8_t</span>, NCCL_ALGO_RING, NCCL_PROTO_SIMPLE)</span><br></pre></td></tr></table></figure></div></li>
<li>这里面的两个宏定义在nccl&#x2F;src&#x2F;device&#x2F;common.h里面：<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> DEFINE_ncclDevKernel(suffix, coll, redop, ty, algo, proto, specializedFnId)                    \</span></span><br><span class="line"><span class="meta">    __global__ void ncclDevKernel_##suffix(ncclDevKernelArgs4K NCCL_GRID_CONSTANT const args4K)        \</span></span><br><span class="line"><span class="meta">    &#123;                                                                                                  \</span></span><br><span class="line"><span class="meta">        ncclKernelMain<span class="string">&lt;specializedFnId, RunWorkBatch&lt;coll, ty, redop&lt;ty&gt;</span>, algo, proto&gt;&gt;(&amp;args4K.args); \</span></span><br><span class="line"><span class="meta">    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DEFINE_ncclDevFunc(suffix, coll, redop, ty, algo, proto) \</span></span><br><span class="line"><span class="meta">    __device__ void ncclDevFunc_##suffix()                       \</span></span><br><span class="line"><span class="meta">    &#123;                                                            \</span></span><br><span class="line"><span class="meta">        RunWorkBatch<span class="string">&lt;coll, ty, redop&lt;ty&gt;</span>, algo, proto&gt;().run();  \</span></span><br><span class="line"><span class="meta">    &#125;</span></span><br></pre></td></tr></table></figure></div></li>
<li>CUDA会通过查找刚刚的<strong>host_table.cc</strong>找到这个<strong>ncclDevKernel_SendRecv</strong>，然后通过这个函数去调用真正的kernel函数（去文件里面搜一下”ncclDevKernel_SendRecv”看一下就大概知道了）</li>
<li>下面我们看看RunWorkBatch是什么东西</li>
</ul>
<h3 id="RunWorkBatch"><a href="#RunWorkBatch" class="headerlink" title="RunWorkBatch"></a>RunWorkBatch</h3><div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">template &lt;ncclFunc_t Fn, typename T, typename RedOp, <span class="type">int</span> Algo, <span class="type">int</span> Proto&gt;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">RunWorkBatch</span>;</span></span><br></pre></td></tr></table></figure></div>
<ul>
<li>这是他的最初原型，在nccl&#x2F;src&#x2F;device&#x2F;sendrecv.h里面，我们可以看到他的一个针对sendrecv的特化：<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">template &lt;typename T, typename RedOp&gt;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">RunWorkBatch</span>&lt;</span>ncclFuncSendRecv, T, RedOp, NCCL_ALGO_RING, NCCL_PROTO_SIMPLE&gt;</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">static_assert</span>(<span class="keyword">sizeof</span>(T) == <span class="number">1</span>, <span class="string">&quot;SendRecv only works on single byte types T.&quot;</span>);</span><br><span class="line"></span><br><span class="line">    template &lt;typename Proto&gt;</span><br><span class="line">    __device__ <span class="type">void</span> <span class="title function_">runSend</span><span class="params">(<span class="type">int</span> tid, <span class="type">int</span> tn, <span class="type">int</span> group, <span class="keyword">struct</span> ncclDevWorkP2p *work)</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">size_t</span> bytes = work-&gt;sendBytes;</span><br><span class="line">        <span class="type">int</span> chunkSize = work-&gt;sendIpcReg &amp;&amp; ncclShmem.comm.isNvlink ? (<span class="number">1</span> &lt;&lt; <span class="number">30</span>) : u32fp8Decode(work-&gt;sendChunkSize_u32fp8);</span><br><span class="line">        Primitives&lt;T, RedOp, FanAsymmetric&lt;<span class="number">0</span>, <span class="number">1</span>&gt;, <span class="number">1</span>, Proto, <span class="number">1</span>&gt;</span><br><span class="line">            prims(tid, tn, nullptr, &amp;work-&gt;sendRank, work-&gt;sendAddr, nullptr,</span><br><span class="line">                  <span class="comment">/*redOpArg(ignored)=*/</span><span class="number">0</span>, group, <span class="number">1</span>, <span class="number">1</span>, nullptr,</span><br><span class="line">                  <span class="comment">/*ipcReg=*/</span>work-&gt;sendIpcReg, <span class="comment">/*netReg=*/</span>work-&gt;sendRegistered, ncclShmem.comm.p2pChunkSize);</span><br><span class="line">        <span class="type">size_t</span> cursor = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">do</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> n = min(<span class="type">size_t</span>(chunkSize), bytes - cursor);</span><br><span class="line">            prims.directSend(cursor, cursor, n);</span><br><span class="line">            cursor += n;</span><br><span class="line">        &#125; <span class="keyword">while</span> (cursor &lt; bytes &amp;&amp; work-&gt;sendRegistered == <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    template &lt;typename Proto&gt;</span><br><span class="line">    __device__ <span class="type">void</span> <span class="title function_">runRecv</span><span class="params">(<span class="type">int</span> tid, <span class="type">int</span> tn, <span class="type">int</span> group, <span class="keyword">struct</span> ncclDevWorkP2p *work)</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">size_t</span> bytes = work-&gt;recvBytes;</span><br><span class="line">        <span class="type">int</span> chunkSize = work-&gt;recvIpcReg &amp;&amp; ncclShmem.comm.isNvlink ? (<span class="number">1</span> &lt;&lt; <span class="number">30</span>) : u32fp8Decode(work-&gt;recvChunkSize_u32fp8);</span><br><span class="line">        Primitives&lt;T, RedOp, FanAsymmetric&lt;<span class="number">1</span>, <span class="number">0</span>&gt;, <span class="number">1</span>, Proto, <span class="number">1</span>&gt;</span><br><span class="line">            prims(tid, tn, &amp;work-&gt;recvRank, nullptr, nullptr, work-&gt;recvAddr,</span><br><span class="line">                  <span class="comment">/*redOpArg(ignored)=*/</span><span class="number">0</span>, group, <span class="number">1</span>, <span class="number">1</span>, nullptr,</span><br><span class="line">                  <span class="comment">/*ipcReg=*/</span>work-&gt;recvIpcReg, <span class="comment">/*netReg=*/</span>work-&gt;recvRegistered, ncclShmem.comm.p2pChunkSize);</span><br><span class="line">        <span class="type">size_t</span> cursor = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">do</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> n = min(<span class="type">size_t</span>(chunkSize), bytes - cursor);</span><br><span class="line">            prims.directRecv(cursor, cursor, n);</span><br><span class="line">            cursor += n;</span><br><span class="line">        &#125; <span class="keyword">while</span> (cursor &lt; bytes &amp;&amp; work-&gt;recvRegistered == <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    __device__ __forceinline__ <span class="type">void</span> <span class="title function_">run</span><span class="params">()</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> tn = blockDim.x;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> wid = tid / WARP_SIZE;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> nWarps = tn / WARP_SIZE;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> lane = tid % WARP_SIZE;</span><br><span class="line"></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">Shared</span></span></span><br><span class="line"><span class="class">        &#123;</span></span><br><span class="line">            <span class="type">uint32_t</span> workSendMask; <span class="comment">// bitmasks of which work indices have send/recv</span></span><br><span class="line">            <span class="type">uint32_t</span> workRecvMask;</span><br><span class="line">        &#125;;</span><br><span class="line">        Shared *shared = (Shared *)ncclScratchForWarp(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">ncclDevWorkP2p</span> *<span class="title">works</span> =</span> (ncclDevWorkP2p *)ncclShmem.workStorage;</span><br><span class="line">        <span class="type">int</span> nWorks = ncclShmem.nWorks;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (wid == <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// Modify the memory range of each work[] to reflect this channel&#x27;s</span></span><br><span class="line">            <span class="comment">// partition of the work. Since integer divides are very heavy it&#x27;s</span></span><br><span class="line">            <span class="comment">// best to do them all in one warp.</span></span><br><span class="line">            <span class="type">int</span> workIx = lane % <span class="number">16</span>;</span><br><span class="line">            <span class="type">int</span> isSend = lane &lt; <span class="number">16</span> ? <span class="number">0</span> : <span class="number">1</span>;</span><br><span class="line">            <span class="type">bool</span> hasWork = <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">if</span> (workIx &lt; nWorks)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="class"><span class="keyword">struct</span> <span class="title">ncclDevWorkP2p</span> *<span class="title">work</span> =</span> &amp;works[workIx];</span><br><span class="line">                <span class="type">size_t</span> bytes = isSend ? work-&gt;sendBytes : work-&gt;recvBytes;</span><br><span class="line">                <span class="type">int</span> nParts = isSend ? work-&gt;nSendChannels : work-&gt;nRecvChannels;</span><br><span class="line">                <span class="type">int</span> part = ncclP2pChannelToPart(work-&gt;nP2pChannels, work-&gt;channelBase, ncclShmem.channelId);</span><br><span class="line">                hasWork = (part &lt; nParts);</span><br><span class="line">                <span class="keyword">if</span> (nParts != <span class="number">0</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="type">size_t</span> partBeg, partEnd;</span><br><span class="line">                    ncclP2pPartBounds(nParts, part, bytes, &amp;partBeg, &amp;partEnd);</span><br><span class="line">                    (isSend ? work-&gt;sendAddr : work-&gt;recvAddr) = (<span class="type">char</span> *)(isSend ? work-&gt;sendAddr : work-&gt;recvAddr) + partBeg;</span><br><span class="line">                    (isSend ? work-&gt;sendBytes : work-&gt;recvBytes) = partEnd - partBeg;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// Coverity reports a possible thread divergence due to not all threads participating in the collective.</span></span><br><span class="line">            <span class="comment">// However, the code ensures that the participation is on a per-warp basis.</span></span><br><span class="line">            <span class="comment">// coverity[device_thread_diverged:FALSE]</span></span><br><span class="line">            <span class="type">uint32_t</span> mask = __ballot_sync(~<span class="number">0u</span>, hasWork);</span><br><span class="line">            <span class="keyword">if</span> (lane == <span class="number">0</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                shared-&gt;workSendMask = mask &gt;&gt; <span class="number">16</span>;</span><br><span class="line">                shared-&gt;workRecvMask = mask &amp; <span class="number">0xffff</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// The fastest way to compute a warp uniform division x/y in [0,32) is to</span></span><br><span class="line">        <span class="comment">// use each lane to guess a solution and count the ones that don&#x27;t exceed</span></span><br><span class="line">        <span class="comment">// the numerator:</span></span><br><span class="line">        <span class="comment">//   __popc(__ballot_sync(~0u, y*(lane+1) &lt;= x))</span></span><br><span class="line">        <span class="comment">// That takes 1/3 the time of standard division and about 3/4 the time of</span></span><br><span class="line">        <span class="comment">// approximate floating point division:</span></span><br><span class="line">        <span class="comment">//   __float2int_rd(__fdividef(float(x),float(y))).</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// nWarpPerWork = nWarps/nWorks</span></span><br><span class="line">        <span class="type">int</span> nWarpPerWork = __popc(__ballot_sync(~<span class="number">0u</span>, nWorks * (lane + <span class="number">1</span>) &lt;= nWarps));</span><br><span class="line">        <span class="type">int</span> nRecvWarpPerWork = nWarpPerWork &lt;= <span class="number">4</span> ? nWarpPerWork / <span class="number">2</span> : (nWarpPerWork - <span class="number">1</span>) / <span class="number">2</span>;</span><br><span class="line">        <span class="type">int</span> nSendWarpPerWork = nWarpPerWork &lt;= <span class="number">4</span> ? nRecvWarpPerWork : nRecvWarpPerWork + <span class="number">1</span>;</span><br><span class="line">        <span class="comment">// This might reduce nWarpPerWork which is probably desirable. It is better</span></span><br><span class="line">        <span class="comment">// to have a balanced number of reading and writing threads even if that</span></span><br><span class="line">        <span class="comment">// leaves warps unused.</span></span><br><span class="line">        nWarpPerWork = nSendWarpPerWork + nRecvWarpPerWork;</span><br><span class="line">        <span class="comment">// The work index this warp belongs to: workIx = wid/nWarpPerWork</span></span><br><span class="line">        <span class="type">int</span> workIx = __popc(__ballot_sync(~<span class="number">0u</span>, (lane + <span class="number">1</span>) * nWarpPerWork &lt;= wid));</span><br><span class="line"></span><br><span class="line">        __syncthreads(); <span class="comment">// Wait for works[] and shared-&gt;* to be updated by warp=0</span></span><br><span class="line"></span><br><span class="line">        <span class="type">uint32_t</span> workSendMask = shared-&gt;workSendMask;</span><br><span class="line">        <span class="type">uint32_t</span> workRecvMask = shared-&gt;workRecvMask;</span><br><span class="line"></span><br><span class="line">        __syncthreads(); <span class="comment">// release scratch space used by shared-&gt;*</span></span><br><span class="line">        <span class="keyword">if</span> (nWorks &lt;= workIx)</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Thread range for whole work (send &amp; recv combined)</span></span><br><span class="line">        <span class="type">int</span> subtid = tid - workIx * nWarpPerWork * WARP_SIZE;</span><br><span class="line">        <span class="type">int</span> subtn = nWarpPerWork * WARP_SIZE;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// A send primtive of sufficient size requires 2 cuda barrier ids.</span></span><br><span class="line">        <span class="type">constexpr</span> <span class="type">int</span> nSendWarpsForExtraGroup = NCCL_SIMPLE_EXTRA_GROUP_IF_NTHREADS_GE / WARP_SIZE;</span><br><span class="line">        <span class="comment">// Count up all group ids used below this workIx:</span></span><br><span class="line">        <span class="type">int</span> group, extra;</span><br><span class="line">        <span class="comment">// Each recv gets one group id:</span></span><br><span class="line">        group = __popc(workRecvMask &amp; ((<span class="number">1</span> &lt;&lt; workIx) - <span class="number">1</span>));</span><br><span class="line">        <span class="comment">// Sends accompanying recvs get one and maybe an extra:</span></span><br><span class="line">        extra = (nSendWarpPerWork &gt;= nSendWarpsForExtraGroup) ? <span class="number">1</span> : <span class="number">0</span>;</span><br><span class="line">        group += __popc((workSendMask &amp; workRecvMask) &amp; ((<span class="number">1</span> &lt;&lt; workIx) - <span class="number">1</span>)) * (<span class="number">1</span> + extra);</span><br><span class="line">        <span class="comment">// Sends without recvs use more warps so compute extra accordingly:</span></span><br><span class="line">        extra = (nWarpPerWork &gt;= nSendWarpsForExtraGroup) ? <span class="number">1</span> : <span class="number">0</span>;</span><br><span class="line">        group += __popc((workSendMask &amp; ~workRecvMask) &amp; ((<span class="number">1</span> &lt;&lt; workIx) - <span class="number">1</span>)) * (<span class="number">1</span> + extra);</span><br><span class="line"></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">ncclDevWorkP2p</span> *<span class="title">work</span> =</span> &amp;works[workIx];</span><br><span class="line">        <span class="type">bool</span> hasSend = <span class="number">1</span> &amp; (workSendMask &gt;&gt; workIx);</span><br><span class="line">        <span class="type">bool</span> hasRecv = <span class="number">1</span> &amp; (workRecvMask &gt;&gt; workIx);</span><br><span class="line">        <span class="type">bool</span> isCopy = work-&gt;sendRank == ncclShmem.comm.rank;</span><br><span class="line">        <span class="type">bool</span> isSend = !hasRecv || (hasSend &amp;&amp; subtid &lt; nSendWarpPerWork * WARP_SIZE);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!isCopy &amp;&amp; hasSend &amp;&amp; hasRecv)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// Translate thread ids to reflect just this send or recv as opposed to whole work.</span></span><br><span class="line">            <span class="keyword">if</span> (isSend)</span><br><span class="line">            &#123;</span><br><span class="line">                subtn = nSendWarpPerWork * WARP_SIZE;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                subtid -= nSendWarpPerWork * WARP_SIZE;</span><br><span class="line">                subtn = nRecvWarpPerWork * WARP_SIZE;</span><br><span class="line">                group += <span class="number">1</span> + (nSendWarpPerWork &gt;= nSendWarpsForExtraGroup ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (isCopy)</span><br><span class="line">        &#123;</span><br><span class="line">            reduceCopy&lt;COLL_UNROLL, RedOp, T, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="comment">/*PreOpSrcs=*/</span><span class="number">0</span>&gt;(subtid, subtn, <span class="number">0</span>, nullptr, <span class="literal">false</span>, <span class="number">1</span>, &amp;work-&gt;sendAddr, <span class="number">1</span>, &amp;work-&gt;recvAddr, (<span class="type">ssize_t</span>)work-&gt;sendBytes);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (isSend)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (work-&gt;sendProtoLL)</span><br><span class="line">            &#123;</span><br><span class="line">                runSend&lt;ProtoLL&gt;(subtid, subtn, group, work);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                runSend&lt;ProtoSimple&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;(subtid, subtn, group, work);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (work-&gt;recvProtoLL)</span><br><span class="line">            &#123;</span><br><span class="line">                runRecv&lt;ProtoLL&gt;(subtid, subtn, group, work);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                runRecv&lt;ProtoSimple&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;(subtid, subtn, group, work);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></div></li>
<li>run里面调用了runSend,runRecv，里面调用了primitives原语，接下来可以前往nccl&#x2F;src&#x2F;device&#x2F;prims_ll128.h等文件查看相关内容</li>
</ul>
]]></content>
      <categories>
        <category>NCCL</category>
      </categories>
      <tags>
        <tag>NCCL</tag>
        <tag>代码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>同步机制</title>
    <url>/2024/12/08/%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h2 id="barrier"><a href="#barrier" class="headerlink" title="barrier"></a>barrier</h2><p>在计算机科学和并行计算中，<strong>barrier</strong>（屏障）是一种同步机制，用于确保一组线程或进程在某个特定点之前都完成其任务，然后才能继续执行后续操作。它的核心功能是强制所有线程或进程“汇合”到某个同步点，并等待所有参与者都到达该点后，才能继续执行。</p>
<h3 id="详细解释"><a href="#详细解释" class="headerlink" title="详细解释"></a>详细解释</h3><h4 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h4><ol>
<li><strong>屏障点</strong>:<ul>
<li>程序中设置一个“屏障点”，所有线程或进程在到达这个点后都会停下来。</li>
<li>只有当所有线程或进程都到达这个屏障点后，它们才可以继续执行。</li>
</ul>
</li>
<li><strong>同步控制</strong>:<ul>
<li>如果有任何线程或进程未到达屏障点，已经到达的线程或进程会被阻塞（等待）。</li>
<li>当最后一个线程或进程到达屏障点时，屏障被解除，所有线程或进程继续执行。</li>
</ul>
</li>
</ol>
<h4 id="用途"><a href="#用途" class="headerlink" title="用途"></a>用途</h4><ul>
<li>确保多个线程或进程在并行计算中同步某个步骤。</li>
<li>协调计算任务的不同阶段，例如：<ul>
<li>数据准备</li>
<li>中间计算</li>
<li>结果合并</li>
</ul>
</li>
</ul>
<h4 id="示例场景"><a href="#示例场景" class="headerlink" title="示例场景"></a>示例场景</h4><p>在并行程序中，每个线程可能负责不同的数据块进行计算。例如，进行矩阵乘法时，每个线程计算一部分矩阵。为了确保所有线程都完成其部分计算（阶段1），可以在阶段结束时使用屏障。只有所有线程都完成了阶段1，程序才能进入阶段2。</p>
<hr>
<h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h3><h4 id="1-线程级屏障"><a href="#1-线程级屏障" class="headerlink" title="1. 线程级屏障"></a>1. <strong>线程级屏障</strong></h4><p>   在多线程程序中（如使用 <code>pthreads</code> 或 OpenMP），可以使用内置屏障机制：</p>
<ul>
<li><strong>Pthreads</strong>:<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">pthread_barrier_t</span> barrier;</span><br><span class="line">pthread_barrier_init(&amp;barrier, <span class="literal">NULL</span>, num_threads);</span><br><span class="line">pthread_barrier_wait(&amp;barrier);</span><br></pre></td></tr></table></figure></div></li>
<li><strong>OpenMP</strong>:<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> omp barrier</span></span><br></pre></td></tr></table></figure></div></li>
</ul>
<h4 id="2-进程级屏障"><a href="#2-进程级屏障" class="headerlink" title="2. 进程级屏障"></a>2. <strong>进程级屏障</strong></h4><p>   在分布式计算中（如使用 MPI），可以使用通信库提供的屏障函数：</p>
<ul>
<li><strong>MPI</strong>:<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">MPI_Barrier(MPI_COMM_WORLD);</span><br></pre></td></tr></table></figure></div></li>
</ul>
<h4 id="3-CUDA-中的屏障"><a href="#3-CUDA-中的屏障" class="headerlink" title="3. CUDA 中的屏障"></a>3. <strong>CUDA 中的屏障</strong></h4><p>   在 CUDA 程序中，可以通过以下方式实现屏障：</p>
<ul>
<li><strong>线程块内屏障</strong>:<div class="code-container" data-rel="C"><figure class="iseeu highlight c"><table><tr><td class="code"><pre><span class="line">__syncthreads();</span><br></pre></td></tr></table></figure></div></li>
<li>注意：<code>__syncthreads</code> 只能用于同一线程块中的线程同步，不能跨线程块。</li>
</ul>
<hr>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ol>
<li><strong>性能问题</strong>: <ul>
<li>屏障可能会引入性能瓶颈，因为所有线程必须等待最慢的线程到达屏障点。</li>
<li>如果线程工作负载不均衡，屏障可能导致资源浪费。</li>
</ul>
</li>
<li><strong>死锁风险</strong>:<ul>
<li>如果部分线程无法到达屏障点（如因错误退出或逻辑问题），整个程序会挂起。</li>
</ul>
</li>
<li><strong>多级屏障</strong>:<ul>
<li>在复杂并行任务中，可以需要设置多级屏障以协调不同的同步点。</li>
</ul>
</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Barrier 是一种用来同步线程或进程的机制，常用于并行和分布式计算中，确保所有参与者都完成某一阶段任务后再进入下一阶段。这在高性能计算中是一个非常重要的概念。</p>
]]></content>
      <categories>
        <category>操作系统知识</category>
      </categories>
      <tags>
        <tag>系统</tag>
      </tags>
  </entry>
  <entry>
    <title>实验室服务器nccl部署命令</title>
    <url>/2024/12/04/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E6%9C%8D%E5%8A%A1%E5%99%A8nccl%E9%83%A8%E7%BD%B2%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h1 id="nccl编译"><a href="#nccl编译" class="headerlink" title="nccl编译"></a>nccl编译</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">make src.build CUDA_HOME=/usr/lib/nvidia-cuda-toolkit/ NVCC_GENCODE=<span class="string">&quot;-gencode=arch=compute_80,code=sm_80&quot;</span></span><br></pre></td></tr></table></figure></div>

<h1 id="查看各种库的安装路径"><a href="#查看各种库的安装路径" class="headerlink" title="查看各种库的安装路径"></a>查看各种库的安装路径</h1><ul>
<li>由于管理员最初好像是用apt安装的，所以可以这样查找</li>
<li>以查找mpi为例<div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">dpkg -S mpicc</span><br></pre></td></tr></table></figure></div></li>
</ul>
<h1 id="nccl-test编译"><a href="#nccl-test编译" class="headerlink" title="nccl-test编译"></a>nccl-test编译</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line">make MPI=1 MPI_HOME=/usr/mpi/gcc/openmpi-4.1.7a1 CUDA_HOME=/usr/lib/nvidia-cuda-toolkit/ NCCL_HOME=/home/cyu/tccl-2024/nccl/build</span><br></pre></td></tr></table></figure></div>

<h1 id="nccl-test测试"><a href="#nccl-test测试" class="headerlink" title="nccl-test测试"></a>nccl-test测试</h1><div class="code-container" data-rel="Bash"><figure class="iseeu highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/home/cyu/tccl-2024/nccl/build/lib:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line">./build/all_reduce_perf -b 8 -e 128M -f 2 -g 2</span><br></pre></td></tr></table></figure></div>]]></content>
      <categories>
        <category>实验室实践</category>
      </categories>
      <tags>
        <tag>nccl</tag>
        <tag>实验室</tag>
      </tags>
  </entry>
</search>
